{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "GNN_MuonE_v1_Robust_mc-recon_comparison.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EyupBunlu/Tracking/blob/master/GNN_MuonE_v1_Robust_mc_recon_comparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_vum9p0R7yZ",
        "colab_type": "text"
      },
      "source": [
        "# Tutorial: GNNs for Particle Tracking\n",
        "\n",
        "HEP.TrkX group\n",
        "\n",
        "Steve Farrell, Daniel Murname\n",
        "\n",
        "*Feb 2020*\n",
        "\n",
        "Adapted for MuonE tracking by Marcin Wolter\n",
        "\n",
        "*July 2020*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZh8UpRMR7yp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "ca63686d-c17a-4660-9541-b6eb73d2d23d"
      },
      "source": [
        "# System imports\n",
        "import os\n",
        "import sys\n",
        "from pprint import pprint as pp\n",
        "from time import time as tt\n",
        "\n",
        "# External imports\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCH4u73YSkuf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "66f137c6-ad81-4a91-909c-1c2c940d19f5"
      },
      "source": [
        "print(\"PyTorch version:\",print(torch.__version__),\", CUDA version:\", torch.version.cuda)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.5.1+cu101\n",
            "PyTorch version: None , CUDA version: 10.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yAAs3ZiTNGX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d14ee9b2-1d8a-4595-da3b-712f3651fbc1"
      },
      "source": [
        "!pip install torch-scatter==latest+cu101 torch-sparse==latest+cu101 -f https://s3.eu-central-1.amazonaws.com/pytorch-geometric.com/whl/torch-1.5.0.html\n",
        "!pip install torch-geometric"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://s3.eu-central-1.amazonaws.com/pytorch-geometric.com/whl/torch-1.5.0.html\n",
            "Collecting torch-scatter==latest+cu101\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.5.0/torch_scatter-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (12.2MB)\n",
            "\u001b[K     |████████████████████████████████| 12.3MB 1.4MB/s \n",
            "\u001b[?25hCollecting torch-sparse==latest+cu101\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.5.0/torch_sparse-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (21.6MB)\n",
            "\u001b[K     |████████████████████████████████| 21.6MB 220kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-sparse==latest+cu101) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->torch-sparse==latest+cu101) (1.18.5)\n",
            "Installing collected packages: torch-scatter, torch-sparse\n",
            "Successfully installed torch-scatter-2.0.5 torch-sparse-0.6.6\n",
            "Collecting torch-geometric\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/18/93b190226d09958be96919fd50c55d28f83f1a1b9260a2b33499f9d86728/torch_geometric-1.6.0.tar.gz (172kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.5.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.18.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (4.41.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.22.2.post1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.48.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.0.5)\n",
            "Collecting rdflib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/6b/6454aa1db753c0f8bc265a5bd5c10b5721a4bb24160fb4faf758cf6be8a1/rdflib-5.0.0-py3-none-any.whl (231kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 11.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.10.0)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.4)\n",
            "Collecting ase\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/70/a8b1a7831193aa228defd805891c534d3e4717c8988147522e673458ddce/ase-3.19.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 12.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.11.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torch-geometric) (0.16.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->torch-geometric) (4.4.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->torch-geometric) (0.16.0)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba->torch-geometric) (0.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba->torch-geometric) (49.1.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2.8.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric) (1.12.0)\n",
            "Collecting isodate\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from ase->torch-geometric) (3.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->torch-geometric) (1.1.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->ase->torch-geometric) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->ase->torch-geometric) (0.10.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-1.6.0-cp36-none-any.whl size=296339 sha256=aa3dec5a74646d8948d1ab161b229327963dae270be1a854bc8fec75da6aed65\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/7f/33/acea5809d8580a7adf60dcd6d04f5fc50a7f983040f68be1ff\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: isodate, rdflib, ase, torch-geometric\n",
            "Successfully installed ase-3.19.1 isodate-0.6.0 rdflib-5.0.0 torch-geometric-1.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YLfHA3uSjL_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch_geometric.data import Data\n",
        "from torch_geometric.data import DataLoader\n",
        "import torch.nn as nn\n",
        "from torch_scatter import scatter_add\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import interact, interact_manual\n",
        "from IPython.display import clear_output\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# Get rid of RuntimeWarnings, gross\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYwHU7mHR7zR",
        "colab_type": "text"
      },
      "source": [
        "## The Problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB6mrc_KR71-",
        "colab_type": "text"
      },
      "source": [
        "The complexity of the graph depends on the angle cut we put on it. Try increasing max_angle to, say, `(5/6)*np.pi` and the graph should be more busy. The limit is of course `(6/6)*np.pi = pi` where each node will look at the full angle of available possible nodes to form an edge with. While playing with this number, run the next cell to see the proportion of fake edges to true edges (fake/true) on the above graph. This value will be extremely useful later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eusssWsdR73x",
        "colab_type": "text"
      },
      "source": [
        "## A Simple GNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1FRm4nsR730",
        "colab_type": "text"
      },
      "source": [
        "### Message Passing GNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gx0VuKz1R732",
        "colab_type": "text"
      },
      "source": [
        "We can write out the full GNN as a class `MPNN_Network`. One can see its behaviour as:\n",
        "1. Encode (x,y) features as hidden features with an N-layer MLP called `node_encoder`\n",
        "2. Concatenate these along each edge, and feed the concatenated features into another MLP called `edge_network`\n",
        "3. Sum the output of `edge_classifier` at each node (that is, each node receives the sum of the \"messages\" of all connecting edges). This sum is fed into `node_network`\n",
        "4. Add the hidden features to the previous iteration (this helps to preserve information between messages)\n",
        "5. Repeat (2) --> (4) n_graph_iters times\n",
        "6. After the message passing loop, pass the features of each edge through an output classifier network called `edge_classifier`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEPycV6mR734",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_mlp(input_size, sizes,\n",
        "             hidden_activation='ReLU',\n",
        "             output_activation='ReLU',\n",
        "             layer_norm=False):\n",
        "    \"\"\"Construct an MLP with specified fully-connected layers.\"\"\"\n",
        "\n",
        "    hidden_activation = getattr(nn, hidden_activation)\n",
        "    if output_activation is not None:\n",
        "        output_activation = getattr(nn, output_activation)\n",
        "    layers = []\n",
        "    n_layers = len(sizes)\n",
        "    sizes = [input_size] + sizes\n",
        "    # Hidden layers\n",
        "\n",
        "    for i in range(n_layers-1):\n",
        "        layers.append(nn.Linear(sizes[i], sizes[i+1]))\n",
        "        if layer_norm:\n",
        "            layers.append(nn.LayerNorm(sizes[i+1]))\n",
        "        layers.append(hidden_activation())\n",
        "\n",
        "    # Final layer\n",
        "    layers.append(nn.Linear(sizes[-2], sizes[-1]))\n",
        "    if output_activation is not None:\n",
        "        if layer_norm:\n",
        "            layers.append(nn.LayerNorm(sizes[-1]))\n",
        "        layers.append(output_activation())\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class MPNN_Network(nn.Module):\n",
        "    \"\"\"\n",
        "    A message-passing graph network which takes a graph with:\n",
        "    - bi-directional edges\n",
        "    - node features, no edge features\n",
        "\n",
        "    and applies the following modules:\n",
        "    - a graph encoder (no message passing)\n",
        "    - recurrent edge and node networks\n",
        "    - an edge classifier\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, hidden_node_dim, hidden_edge_dim, in_layers, node_layers, edge_layers,\n",
        "                 n_graph_iters=1, layer_norm=True,normalize_factor= 1):\n",
        "        super(MPNN_Network, self).__init__()\n",
        "        self.n_graph_iters = n_graph_iters\n",
        "\n",
        "        # The node encoder transforms input node features to the hidden space\n",
        "        self.node_encoder = make_mlp(input_dim, [hidden_node_dim]*in_layers)\n",
        "\n",
        "        # The edge network computes new edge features from connected nodes\n",
        "        self.edge_network = make_mlp(2*hidden_node_dim,\n",
        "                                     [hidden_edge_dim]*edge_layers,\n",
        "                                     layer_norm=layer_norm)\n",
        "\n",
        "        # The node network computes new node features\n",
        "        self.node_network = make_mlp(hidden_node_dim + hidden_edge_dim,\n",
        "                                     [hidden_node_dim]*node_layers,\n",
        "                                     layer_norm=layer_norm)\n",
        "\n",
        "        # The edge classifier computes final edge scores\n",
        "        self.edge_classifier = make_mlp(2*hidden_node_dim,\n",
        "                                        [hidden_edge_dim, 1],\n",
        "                                        output_activation=None)\n",
        "        self.normalize_factor=normalize_factor\n",
        "    def forward(self, data):\n",
        "        # Make every edge bi-directional\n",
        "        send_idx = torch.cat([data.edge_index[0], data.edge_index[1]], dim=0)\n",
        "        recv_idx = torch.cat([data.edge_index[1], data.edge_index[0]], dim=0)\n",
        "        \n",
        "        # Encode the graph features into the hidden space\n",
        "        #print( torch.mean (data.x[:,0]) )\n",
        "        #print( torch.mean (data.x[:,1]) )\n",
        "        if self.normalize_factor!=1:\n",
        "          temp = data.x.clone().detach()\n",
        "          temp[:,1] *= self.normalize_factor\n",
        "          x = self.node_encoder(temp)\n",
        "        else:\n",
        "          x = self.node_encoder(data.x.clone().detach())\n",
        "        # Loop over graph iterations\n",
        "        for i in range(self.n_graph_iters):\n",
        "\n",
        "            # Previous hidden state\n",
        "            x0 = x\n",
        "\n",
        "            # Compute new edge features\n",
        "            edge_inputs = torch.cat([x[send_idx], x[recv_idx]], dim=1)\n",
        "            e = self.edge_network(edge_inputs)\n",
        "\n",
        "            # Sum edge features coming into each node\n",
        "            aggr_messages = scatter_add(e, recv_idx, dim=0, dim_size=x.shape[0])\n",
        "\n",
        "            # Compute new node features\n",
        "            node_inputs = torch.cat([x, aggr_messages], dim=1)\n",
        "            x = self.node_network(node_inputs)\n",
        "\n",
        "            # Residual connection\n",
        "            x = x + x0\n",
        "\n",
        "        # Compute final edge scores; use original edge directions only\n",
        "        start_idx, end_idx = data.edge_index\n",
        "        clf_inputs = torch.cat([x[start_idx], x[end_idx]], dim=1)\n",
        "        return self.edge_classifier(clf_inputs).squeeze(-1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOsNvEEpR74O",
        "colab_type": "text"
      },
      "source": [
        "Build a version of the model and print it out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fPSN18uR74Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "m_configs = {\"input_dim\": 2, \"hidden_node_dim\": 64, \"hidden_edge_dim\": 64, \"in_layers\": 2, \"node_layers\": 4, \"edge_layers\": 4, \"n_graph_iters\": 1, \"layer_norm\": True}\n",
        "model = MPNN_Network(**m_configs).to(device)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSM30cK2R746",
        "colab_type": "text"
      },
      "source": [
        "### Training and Validation Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQrAmWD23j0x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, train_loader, optimizer):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        data = batch.to(device)\n",
        "        pred = model(data)\n",
        "        loss = F.binary_cross_entropy_with_logits(pred.float(), data.y.float(), pos_weight=torch.tensor(weight))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        correct += ((pred > 0.5) == (data.y > 0.5)).sum().item()\n",
        "        total += len(pred)\n",
        "    acc = correct/total\n",
        "    return acc, total_loss\n",
        "\n",
        "def evaluate(model, test_loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    total_loss = 0\n",
        "    for batch in test_loader:\n",
        "        data = batch.to(device)\n",
        "        pred = model(data)\n",
        "        loss = F.binary_cross_entropy_with_logits(pred.float(), data.y.float(), pos_weight=torch.tensor(weight))\n",
        "        total_loss += loss.item()\n",
        "        correct += ((pred > 0.5) == (data.y > 0.5)).sum().item()\n",
        "        total += len(pred)\n",
        "    acc = correct/total\n",
        "    return acc, total_loss"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wbNjVo3R75N",
        "colab_type": "text"
      },
      "source": [
        "We set a weight value that is more or less the (fake / true) ratio found above. This forces the loss function to punish incorrectly classified true edges more severely. It rebalances the distribution as if there was a 1:1 true:fake ratio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEDdFqVnR75x",
        "colab_type": "text"
      },
      "source": [
        "### Did it work?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fTa4sHsR75z",
        "colab_type": "text"
      },
      "source": [
        "Running the above with 1 graph iteration gives me about 90% accuracy in 200 epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lT5s0J70R751",
        "colab_type": "text"
      },
      "source": [
        "The best performance that I can get with some simple manual tuning is around 95% accuracy. We can improve the efficiency at the cost of purity by raising the weight on true edges, but the accuracy won't significantly improve. In general, the biggest changes were from increasing the width (i.e. the number of dimensions) of the hidden layers. We can visualise the performance on a particular graph, colouring true positives black, false positives red, true negatives a transparent black, and false negatives in blue."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6CR0cLcR752",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_toy_classified(event, preds, cut=0.5):\n",
        "    \n",
        "    #print(\"New event\")\n",
        "        \n",
        "    #print(event)\n",
        "    #print(event.x)\n",
        "    #print(event.pid)\n",
        "    #print(event.y)\n",
        "    #gprint(preds)\n",
        "\n",
        "    plt.figure(figsize=(10,5))\n",
        "    x, y = event.x[:,0].numpy(), event.x[:,1].numpy()\n",
        "    edges = event.edge_index.numpy()\n",
        "    labels = event.y\n",
        "    plt.scatter(x, y, c='k')\n",
        "    \n",
        "    preds = preds.detach().numpy()\n",
        "    \n",
        "\n",
        "    for j in range(len(labels)):\n",
        "        \n",
        "        #print(str('%01.2f' % preds[j])+\" \"+str(labels[j].item())+\" \"+str(x[edges[0,j]]*feature_scale)+\",\"+str(y[edges[0,j]]*feature_scale)+\" \"+str(x[edges[1,j]]*feature_scale)+\",\"+str(y[edges[1,j]]*feature_scale))\n",
        "        s = str('%01.2f' % preds[j])+\" \"+str(labels[j].item())\n",
        "        plt.text((x[edges[0,j]]+x[edges[1,j]])/2., (y[edges[0,j]]+y[edges[1,j]])/2.+np.random.random(1)*0.00, s, fontsize=12)\n",
        "\n",
        "        # False negatives\n",
        "        if preds[j] < cut and labels[j].item() > cut:\n",
        "            plt.plot([x[edges[0,j]], x[edges[1,j]]],\n",
        "                     [y[edges[0,j]], y[edges[1,j]]],\n",
        "                     '--', c='b')\n",
        "\n",
        "        # False positives\n",
        "        if preds[j] > cut and labels[j].item() < cut:\n",
        "            plt.plot([x[edges[0,j]], x[edges[1,j]]],\n",
        "                     [y[edges[0,j]], y[edges[1,j]]],\n",
        "                     '-', c='r', alpha=preds[j])\n",
        "\n",
        "        # True positives\n",
        "        if preds[j] > cut and labels[j].item() > cut:\n",
        "            plt.plot([x[edges[0,j]], x[edges[1,j]]],\n",
        "                     [y[edges[0,j]], y[edges[1,j]]],\n",
        "                     '-', c='k', alpha=preds[j])\n",
        "                \n",
        "        # True negatives\n",
        "        if preds[j] < cut and labels[j].item() < cut:\n",
        "            plt.plot([x[edges[0,j]], x[edges[1,j]]],\n",
        "                     [y[edges[0,j]], y[edges[1,j]]],\n",
        "                     '-', c='k', alpha=preds[j])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIo7EeyJR76L",
        "colab_type": "text"
      },
      "source": [
        "So we can see that it's working quite well. Few missed true edges, and few misclassified fake edges. The ratio of false positives to false negatives (which can be defined with efficiency and purity) is controlled by the cut we put on the prediction score. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CBDsYlxR76N",
        "colab_type": "text"
      },
      "source": [
        "### The effect of Message Passing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSZzzAtDR76P",
        "colab_type": "text"
      },
      "source": [
        "In this simple example, the message passing does not do a huge amount. Going from 1 iteration to 6 iterations improves the accuracy to around 93% (from 90%). This improvement is washed out with more hidden dimensions, as one can see from the below set of tests. Try playing with more hidden node and edge dimensions (e.g. 64) and see if the message passing iterations can improve the performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7koxeu9q4Gn",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "# **Load MuonE data and reconstruct tracks**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Vk18NYQOrfzB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "84741b7f-e8d3-46f5-92fb-cedc0925f30a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xZs_yxD3FRKf",
        "colab": {}
      },
      "source": [
        "# Circle parameters\n",
        "num_layers = 14\n",
        "height, width = 10, 10\n",
        "#min_curve, max_curve =  1000, 1001 # 15, 50\n",
        "\n",
        "max_angle = (0.05)*np.pi\n",
        "feature_scale = 200."
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgK9yW_ErILc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "  \n",
        "def readMuonE(event_file,is_x=True):\n",
        "\n",
        "\n",
        "   data = pd.read_csv(event_file) \n",
        "   # Preview the first 5 lines of the loaded data \n",
        "   data.head()\n",
        "\n",
        "   if is_x:\n",
        "    axis_oi=0\n",
        "    layer_pair=1\n",
        "   else:\n",
        "    layer_pair=0\n",
        "    axis_oi=1\n",
        "\n",
        "   \n",
        "   \n",
        "   \n",
        "   # Temporary nextZ  (next layer Z)\n",
        "   layerZ0 =  [-999, -16, -21, 131, 151, 477, 497, 832, 843.7, 1146, 1141, 1252.7, 1266, 1973, 1960 ]\n",
        "\n",
        "\n",
        "\n",
        "   #X = np.array([[0,0,0]])\n",
        "   #print(X)\n",
        "   \n",
        "   \n",
        "   iEventLast=data.iat[0,0]\n",
        "   k=0\n",
        "   Xcreated=False\n",
        "   #dataOUTcreated=False\n",
        "   dataOUT = []\n",
        "\n",
        "   #iterate over input data\n",
        "   for k, row in data.iterrows():\n",
        "     ll=data.iat[k,0]\n",
        "     #print(\"counter \",k,ll,iEventLast)\n",
        "     if ll != iEventLast:\n",
        "\n",
        "       '''\n",
        "       for layer in np.arange(num_layers-1):\n",
        "          print(\"XX=\",layer,X)\n",
        "          for i in np.argwhere(X[:,2] == layerZ0[layer+1]): \n",
        "            for j in np.argwhere(X[:,2] == layerZ0[layer+3]):\n",
        "               if (X[i, 0] - 20. < X[j, 0] < X[i, 0] + 20.):\n",
        "                   print(\"layer, i, j=\",layer, i, j)\n",
        "       '''\n",
        "#       e = np.array([[i,j] for layer in np.arange(num_layers-1) for i in np.argwhere(X[:,2] == layer+1) for j in np.argwhere(X[:,2] == (layer+2))  if (X[i, 0] - np.tan(max_angle/2) < X[j, 0] < X[i, 0] + np.tan(max_angle/2))]).T.squeeze()\n",
        "\n",
        "       e = np.array([[i,j] for layer in np.arange(num_layers-1) for i in np.argwhere(X[:,2] == \n",
        "              layerZ0[layer+1]) for j in np.argwhere(X[:,2] == layerZ0[layer+3])  if (X[i, 0] - np.tan(max_angle/2)*(layerZ0[layer+3]-layerZ0[layer+1]) < X[j, 0] < X[i, 0] + np.tan(max_angle/2)*(layerZ0[layer+3]-layerZ0[layer+1]))]).T.squeeze()\n",
        "\n",
        "       #print(X)\n",
        "       #print(\"e \",e) \n",
        "        # This handles when no edges were constructed. In that case, the randomisation is a do-over\n",
        "       #try:\n",
        "       y = np.array([int(i[1] == j[1]) for i,j in zip(X[e[0]], X[e[1]])])\n",
        "       #     print(\"y = \",y)     \n",
        "       #     break\n",
        "       #except:\n",
        "       #     pass\n",
        "\n",
        "       #print(\"y = \",y) \n",
        "       #if iter is not None and num_samples is not None:\n",
        "       #     out.update(progress(iter, num_samples))    \n",
        "\n",
        "\n",
        "       X = np.array([X[:,2], X[:,0]]).T / feature_scale\n",
        "\n",
        "       dataEvent = Data(x = torch.from_numpy(X).float(), edge_index = torch.from_numpy(e), y = torch.from_numpy(y), pid = torch.from_numpy(X[:,1])  )\n",
        "\n",
        "       #plot_toy_graph(dataEvent, 0.2)\n",
        "\n",
        "       dataOUT.append(dataEvent)\n",
        "#       if dataOUTcreated:\n",
        "#         dataOUT = dataOUT.append(dataEvent)\n",
        "#       else:\n",
        "#         dataOUT = dataEvent \n",
        "#         dataOUTcreated = True\n",
        "\n",
        "       Xcreated = False  \n",
        "       iEventLast = ll\n",
        "\n",
        "     #print(len(X)) \n",
        "     #print(k,ll,data.iat[k,2],Xcreated) \n",
        "     if data.iat[k,2]==axis_oi and data.iat[k,5]<3 and data.iat[k,5]>=0: #remove equal to part if you don't want to  # select X-hit and trackID=0,1,2\n",
        "        if Xcreated:\n",
        "          X = np.append(X,np.array([[data.iat[k,1], data.iat[k,5], data.iat[k,3]  ]]),axis=0)\n",
        "        else:\n",
        "          X = np.array([[data.iat[k,1], data.iat[k,5], data.iat[k,3]  ]]) \n",
        "          Xcreated=True\n",
        "          #print(\"X created \",X)\n",
        "     \n",
        "   return dataOUT       \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Reads original monte carlo File\n",
        "\n",
        "def readMCtrack(event_file, is_x= True ):\n",
        "\n",
        "  data = pd.read_csv(event_file) \n",
        "  # Preview the first 5 lines of the loaded data \n",
        "  data.head()\n",
        "\n",
        "  if is_x:\n",
        "    axis_oi=[4,1]\n",
        "  else  :\n",
        "    axis_oi=[5,2]\n",
        "\n",
        "  temp=data.iat[-1,0]\n",
        "  track_slopes=torch.zeros(temp,6)\n",
        "\n",
        "  for k, row in data.iterrows():\n",
        "\n",
        "    if (data.iat[k,7]==np.array([0,1,2])).any():\n",
        "\n",
        "      \n",
        "\n",
        "      if track_slopes.shape[0]< data.iat[k,0]-1 :\n",
        "        track_slopes=torch.cat([track_slopes,torch.zeros(1,6)],dim=0)\n",
        "      \n",
        "      \n",
        "      track_slopes[data.iat[k,0]-1,data.iat[k,7]*2 ] = data.iat[k,axis_oi[0]]/data.iat[k,6]\n",
        "\n",
        "      track_slopes[data.iat[k,0]-1,data.iat[k,7]*2+1] =  data.iat[k,axis_oi[1]] - data.iat[k,axis_oi[0]]/data.iat[k,6]  * data.iat[k,3]\n",
        "  \n",
        "  return track_slopes\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Reads From Reconstruction File\n",
        "\n",
        "def ReadRecon(event_file,is_x=True):\n",
        "  data = pd.read_csv(event_file)  \n",
        "  data.head()\n",
        "\n",
        "  if is_x:\n",
        "    axis_oi=[3,1,7,5,9]\n",
        "  else:\n",
        "    axis_oi=[4,2,8,6,9]\n",
        "\n",
        "  track_=torch.zeros(data.iat[-1,0],10)\n",
        "\n",
        "  for k,row in enumerate(data.iterrows()):\n",
        "\n",
        "    if k % 2 ==0:\n",
        "      #track_[data.iat[k,0]-1,0],track_[data.iat[k,0]-1,1]=data.iat[k,axis_oi[0]],data.iat[k,axis_oi[1]]\n",
        "      for i in range( len(axis_oi) ):\n",
        "        track_[data.iat[k,0]-1,i]=data.iat[k,axis_oi[i]]\n",
        "    else:\n",
        "      #track_[data.iat[k,0]-1 ,2],track_[data.iat[k,0]-1,3]=data.iat[k,axis_oi[0]],data.iat[k,axis_oi[1]]\n",
        "      for i in range( len(axis_oi) ):\n",
        "        track_[data.iat[k,0]-1,i+5]=data.iat[k,axis_oi[i]]\n",
        "  print(k)\n",
        "  \n",
        "\n",
        "  temp=track_.clone()\n",
        "  for i in range(data.iat[-1,0]):\n",
        "    if torch.abs(temp[i,0])>torch.abs(temp[i,5]):\n",
        "\n",
        "      track_[i,0:4]=temp[i,5:9]\n",
        "      track_[i,5:9]=temp[i,0:4]\n",
        "\n",
        "\n",
        "\n",
        "  return track_\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zhaE3IHvLwu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "72c761b9-fafd-49f9-b492-a4b633fff1ae"
      },
      "source": [
        "# Read data and prepare for training\n",
        "\n",
        "is_x = True\n",
        "is_y = False\n",
        "event_file_MC= \"/content/drive/My Drive/MCtrackFile_medium.csv\"\n",
        "event_file= \"/content/drive/My Drive/hitFile_medium.csv\"\n",
        "event_file_recon= \"/content/drive/My Drive/trackFile_medium.csv\"\n",
        "\n",
        "Tracks=readMCtrack(event_file_MC,is_x)\n",
        "data = readMuonE(event_file,is_x)\n",
        "Tracks_recon=ReadRecon(event_file_recon,is_x)\n",
        "\n",
        "#Tracks_x=readMCtrack(event_file_MC,is_x)\n",
        "#data_x = readMuonE(event_file,is_x)\n",
        "#Tracks_recon_x=ReadRecon(event_file_recon,is_x)\n",
        "\n",
        "# split data into training and test datasets\n",
        "train_dataset,test_dataset,test_tracks,train_tracks,train_recon,test_recon = [],[],[],[],[],[]\n",
        "\n",
        "for k in range(len(data)):\n",
        "  if (k%4 == 0):\n",
        "    test_dataset.append(data[k])\n",
        "    test_tracks.append(Tracks[k,:])\n",
        "    test_recon.append(Tracks_recon[k,:])\n",
        "  else:\n",
        "    train_dataset.append(data[k])\n",
        "    train_tracks.append(Tracks[k,:])\n",
        "    train_recon.append(Tracks_recon[k,:])\n",
        "train_loader = DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=100, shuffle=True)    \n",
        "\n",
        "# Display few events\n",
        "#for k in range(10):\n",
        " #  plot_toy_graph(train_loader.dataset[k], 0.2)\n",
        "\n",
        "\n",
        "print(\"Fake / True = \", (len(train_dataset[0].y) - train_dataset[0].y.sum().item()) / train_dataset[0].y.sum().item())\n",
        "print(\"Fake / True = \", (len(test_dataset[0].y) - test_dataset[0].y.sum().item()) / test_dataset[0].y.sum().item())\n",
        "\n",
        "print(\"Training dataset (events): \",len(train_dataset))\n",
        "print(\"Test dataset (events): \",len(test_dataset))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19073\n",
            "Fake / True =  1.0\n",
            "Fake / True =  0.875\n",
            "Training dataset (events):  7499\n",
            "Test dataset (events):  2500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6jkuybVoBqw",
        "colab_type": "text"
      },
      "source": [
        "# **Simple GNN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vj7GJA-_okqv"
      },
      "source": [
        "We set a weight value that is more or less the (fake / true) ratio found above. This forces the loss function to punish incorrectly classified true edges more severely. It rebalances the distribution as if there was a 1:1 true:fake ratio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2qlRvrHbokqw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e110d69e-64ca-4f2d-c5b3-b1c9a0a14486"
      },
      "source": [
        "t_loss_v = []\n",
        "t_acc_v = []\n",
        "v_loss_v = []\n",
        "v_acc_v = []\n",
        "ep = 0\n",
        "\n",
        "weight = 1\n",
        "m_configs = {'normalize_factor': 2000 ,\"input_dim\": 2, \"hidden_node_dim\": 64, \"hidden_edge_dim\": 64, \"in_layers\": 1, \"node_layers\": 2, \"edge_layers\": 2, \"n_graph_iters\": 6, \"layer_norm\": True}\n",
        "model = MPNN_Network(**m_configs).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-3, amsgrad=True)\n",
        "\n",
        "for epoch in range(52):\n",
        "    ep += 1  \n",
        "    model.train()\n",
        "    acc_t, total_loss = train(model, train_loader, optimizer)\n",
        "    t_loss_v.append(total_loss)\n",
        "    t_acc_v.append(acc_t)\n",
        "\n",
        "    model.eval()\n",
        "    acc, total_loss = evaluate(model, test_loader)\n",
        "    v_loss_v.append(total_loss)\n",
        "    v_acc_v.append(acc)\n",
        "    if ep % 5 ==1 :\n",
        "      print('Epoch: {}, Accuracy: {:.4f}'.format(ep, acc,acc_t))\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, Accuracy: 0.9769\n",
            "Epoch: 6, Accuracy: 0.9944\n",
            "Epoch: 11, Accuracy: 0.9956\n",
            "Epoch: 16, Accuracy: 0.9965\n",
            "Epoch: 21, Accuracy: 0.9961\n",
            "Epoch: 26, Accuracy: 0.9967\n",
            "Epoch: 31, Accuracy: 0.9971\n",
            "Epoch: 36, Accuracy: 0.9964\n",
            "Epoch: 41, Accuracy: 0.9973\n",
            "Epoch: 46, Accuracy: 0.9974\n",
            "Epoch: 51, Accuracy: 0.9972\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qgTQxer7okq8",
        "colab": {}
      },
      "source": [
        "fig, axs = plt.subplots(1, 2, constrained_layout=True, figsize=(10, 5))\n",
        "\n",
        "axs[0].plot(np.arange(len(t_loss_v)), t_loss_v)\n",
        "axs[0].twinx().plot(np.arange(len(t_acc_v)), t_acc_v,\"r\")\n",
        "axs[0].set_title(\"Training loss and accuracy\")\n",
        "axs[0].set_yscale(\"linear\")\n",
        "axs[1].plot(np.arange(len(v_loss_v)), v_loss_v)\n",
        "axs[1].twinx().plot(np.arange(len(v_acc_v)), v_acc_v,\"r\")\n",
        "axs[1].set_title(\"Validation loss and accuracy\")\n",
        "axs[1].set_yscale(\"linear\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ry91JU8tokrG"
      },
      "source": [
        "### Did it work?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ti-OFV5cokrM",
        "colab": {}
      },
      "source": [
        "for i in range(0,1500):\n",
        "  data = test_loader.dataset[i].to(device)\n",
        "  preds = torch.sigmoid(model(data)).to('cpu')  \n",
        "  \n",
        "  a=0\n",
        "  for j in range(preds.shape[0]):\n",
        "    if preds[j] > 0.5 and preds[j] < 0.8 and 0 :   \n",
        "      a=1\n",
        "  if a==1:\n",
        "    plot_toy_classified(data.to('cpu'), preds, cut = 0.6)\n",
        "  \n",
        "\n",
        "  #plot_toy_graph(train_loader.dataset[2],0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sq3gU_arP2S6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import (\n",
        "    LinearRegression, TheilSenRegressor, RANSACRegressor, HuberRegressor)\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn import linear_model\n",
        "\n",
        "from scipy.optimize import curve_fit, least_squares\n",
        "from scipy import stats\n",
        "\n",
        "\n",
        "def finder(data,y,cut=0.5):\n",
        "  x = data.x.clone().numpy()\n",
        "  edge_index=data.edge_index.detach().numpy()\n",
        "  node_identifier=np.zeros( list(x.shape)[0] )\n",
        "  k=edge_index.shape[1]\n",
        "  y=y.detach().tolist()\n",
        "  is_connected=[]\n",
        "  for i in range(k):\n",
        "    if y[i]-cut>=0:\n",
        "      is_connected.append( True )\n",
        "    else:\n",
        "      is_connected.append( False )\n",
        "\n",
        "  for j in range(1,4):\n",
        "\n",
        "    a=np.where( node_identifier==0 )\n",
        "    if j==1:\n",
        "      try:\n",
        "        min=np.min(np.abs(x[a,0]))\n",
        "      except:\n",
        "        print('oopsie')\n",
        "        break\n",
        "      idx=np.where(np.abs(x[:,0])==min)\n",
        "    \n",
        "\n",
        "    else:\n",
        "      try:\n",
        "        min=np.min(np.abs(x[a,1]))\n",
        "      except:\n",
        "        print('oopsie')\n",
        "        break\n",
        "      idx=np.where(np.abs(x[:,1])==min)\n",
        "    \n",
        "    try:\n",
        "      idx=idx[0]\n",
        "    except:\n",
        "      pass\n",
        "    \n",
        "    neighbor = 1\n",
        "    node_identifier[idx] = j\n",
        "    \n",
        "    \n",
        "    while neighbor :\n",
        "\n",
        "      neighbor = []\n",
        "      try:\n",
        "        idx=idx[-1]\n",
        "      except:\n",
        "        pass\n",
        "      in_neighbor = [ int(edge_index[0,i]) for i in range(k) if int(edge_index[1,i])==idx if is_connected[i] \n",
        "                     if node_identifier[ edge_index[0,i] ] ==0  ]\n",
        "\n",
        "      ot_neighbor = [ int(edge_index[1,i]) for i in range(k) if int(edge_index[0,i])==idx if is_connected[i] \n",
        "                     if node_identifier[ edge_index[1,i] ] ==0  ]\n",
        "      neighbor = in_neighbor + ot_neighbor\n",
        "      \n",
        "      if len(neighbor)>0:\n",
        "        for i in reversed( range( len(neighbor) ) ):\n",
        "          if node_identifier[neighbor[i]] != 0 :\n",
        "            del neighbor[i]\n",
        "      \n",
        "\n",
        "      if neighbor:\n",
        "        idx=neighbor[0]\n",
        "\n",
        "      node_identifier[neighbor] = j\n",
        "\n",
        "\n",
        "\n",
        "  return node_identifier\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def fit(x,a,b): \n",
        "  return a*x+b\n",
        "def chi2(x,y,yerr,fit,popt):\n",
        "  # Now calculate chi square \n",
        "  yexp = fit(x, *popt)\n",
        "  r_ = (y - yexp)/yerr\n",
        "  chisq_ = np.sum(r_**2)\n",
        "  df_ = len(x) - 2\n",
        "  return chisq_, df_, r_\n",
        "\n",
        "\n",
        "\n",
        "def robust_fit(data,preds,toleration=0.5):\n",
        "  node_lines = finder(data,preds)\n",
        "  x,y=data.x[:,0].clone().numpy()*feature_scale,data.x[:,1].clone().numpy()*feature_scale\n",
        "  \n",
        "  parameters=[]\n",
        "  errors=[]\n",
        "  popt=[]\n",
        "  pcov=[]\n",
        "  for i in range(2,4):\n",
        "    \n",
        "    nodes=np.where(node_lines==i)\n",
        "    \n",
        "    if np.size(nodes)>1 :\n",
        "\n",
        "      yerr = np.ones( np.size(nodes) )*0.03\n",
        "      popt,pcov=curve_fit(fit,x[nodes],y[nodes],p0=(0.0,0.0),sigma=yerr, absolute_sigma=True) \n",
        "\n",
        "      a=popt[0]\n",
        "      err_a=np.sqrt(pcov[0,0])\n",
        "      b=popt[1]\n",
        "      err_b=np.sqrt(pcov[1,1])\n",
        "      chisq_limit = toleration \n",
        "\n",
        "      chisq, df, r = chi2(x[nodes],y[nodes],yerr,fit,popt)\n",
        "      chisq_=[]\n",
        "      if int(chisq/df > chisq_limit) and np.size(nodes)>3  :\n",
        "        for ii in range(np.size(nodes)):\n",
        "\n",
        "          x_robust = np.delete(x[nodes],ii)\n",
        "          y_robust = np.delete(y[nodes],ii)\n",
        "          yerrii = np.delete(yerr,ii)\n",
        "          popt,pcov=curve_fit(fit , x_robust , y_robust , p0=(0.0,0.0),sigma=yerrii, absolute_sigma=True)\n",
        "          chisq, df, r = chi2(x_robust,y_robust,yerrii,fit,popt)      \n",
        "          chisq_.append(chisq)\n",
        "\n",
        "        ii=np.where(np.array(chisq_)==np.amin(np.array(chisq_)))[0] \n",
        "        \n",
        "        x_robust = np.delete(x[nodes],ii)\n",
        "        y_robust = np.delete(y[nodes],ii)\n",
        "        yerr = np.delete(yerr,ii)\n",
        "        popt,pcov=curve_fit(fit , x_robust , y_robust , p0=(0.0,0.0),sigma=yerr, absolute_sigma=True)\n",
        "        chisq, df, r = chi2(x_robust,y_robust,yerr,fit,popt)      \n",
        "          \n",
        "\n",
        "\n",
        "\n",
        "      #if int(chisq/df > chisq_limit) and np.size(nodes)>3  :\n",
        "    # Find outlier and remove it\n",
        "\n",
        "    # find point with the highest abs(r)\n",
        "        #ii = np.where( np.abs(r) == np.amax(abs(r)))[0]\n",
        "\n",
        "        #x_robust = np.delete(x[nodes],ii)\n",
        "        #y_robust = np.delete(y[nodes],ii)\n",
        "        #yerr = np.delete(yerr,ii)\n",
        "    # repeat fit without outlier\n",
        "        #popt,pcov=curve_fit(fit , x_robust , y_robust , p0=(0.0,0.0),sigma=yerr, absolute_sigma=True)\n",
        "        #chisq, df, r = chi2(x_robust,y_robust,yerr,fit,popt)      \n",
        "\n",
        "\n",
        "      a=popt[0]\n",
        "      err_a=np.sqrt(pcov[0,0])\n",
        "      b=popt[1]\n",
        "      err_b=np.sqrt(pcov[1,1])    \n",
        "      parameters.append([a,b])\n",
        "      errors.append([err_a,err_b,yerr,chisq])\n",
        "\n",
        "    \n",
        "    else :\n",
        "      errors.append('N/A')\n",
        "      parameters.append('N/A')\n",
        "\n",
        "  return parameters,errors,node_lines\n",
        "\n",
        "\n",
        "\n",
        "def plot_classified_line(data,preds,Track,trackre ):\n",
        "\n",
        "  parameters_,errors_,node_lines=robust_fit(data,preds)\n",
        "  x,y=data.x[:,0]*feature_scale,data.x[:,1]*feature_scale\n",
        "  colors={'1':'r','2':'g','3':'b' }\n",
        "  fig=plt.figure(figsize=(10,10))\n",
        "  ax=fig.add_subplot(111)\n",
        "\n",
        "  if (node_lines==0).any()== True:\n",
        "    nodes=np.where(node_lines==0)\n",
        "    plt.plot(x[nodes],y[nodes], 'k'+'o' , label = 'Not Track')\n",
        "    \n",
        "  for i in range(1,4):\n",
        "    \n",
        "    nodes=np.where(node_lines==i)\n",
        "    plt.plot(x[nodes],y[nodes],colors[str(i)] +'o' )\n",
        "    nodes=np.where(node_lines==i)\n",
        "\n",
        "\n",
        "  for i in [2,3]:\n",
        "    \n",
        "    nodes=np.where(node_lines==i)\n",
        "    \n",
        "\n",
        "\n",
        "    if np.size(nodes)>1 :\n",
        "      \n",
        "      error=errors_[i-2]  \n",
        "      \n",
        "\n",
        "      x_guess=np.linspace(0,torch.max(x[nodes]),100)\n",
        "      x_line=np.linspace(torch.min(x[nodes]),torch.max(x[nodes]),100)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      # Plotting of original MC tracks\n",
        "\n",
        "\n",
        "      slope_mc = Track[2*i-2]\n",
        "      c_mc = Track[2*i-1]\n",
        "      #c_mc=c_gnn\n",
        "      \n",
        "      \n",
        "      plt.plot(x_guess,c_mc + torch.tensor(x_guess)*slope_mc,'k',label='MC Track', alpha=0.4) \n",
        "      \n",
        "\n",
        "      # Plotting of the GNN\n",
        "      \n",
        "      slope_gnn=parameters_[i-2][0]\n",
        "      c_gnn=parameters_[i-2][1] \n",
        "      \n",
        "      plt.plot(x_guess,c_gnn + torch.tensor(x_guess)*slope_gnn,'--'+colors[str(i)],label=\"GNN{} Error: {:e}, \".format(i-1, \n",
        "          torch.abs( np.round( ( slope_mc - slope_gnn ) /error[0] ,2) ).tolist() ))\n",
        "      \n",
        "      \n",
        "      # Plotting of the regular reconstruction\n",
        "\n",
        "      slope_recon_ = trackre[5*i-10]\n",
        "      c_recon = trackre[5*i-9]  \n",
        "      error_recon_ = trackre[5*i-8]\n",
        "      \n",
        "      plt.plot( torch.tensor(x_line), torch.tensor(x_line) * slope_recon_ + c_recon ,colors[str(i)], label=r\"recon{} Error: {:e}, \".format(i-1, \n",
        "          torch.abs( np.round( (slope_mc-slope_recon_)/error_recon_ ,2) ).tolist() )  )   \n",
        "      \n",
        "\n",
        "            \n",
        "      ax.errorbar(x[nodes],y[nodes],yerr= np.ones(np.size(nodes,1) )*0.03,fmt='none', ecolor=colors[str(i)] )\n",
        "  plt.legend()\n"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8gsImHWJeRE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for i in range(len(train_loader.dataset)):\n",
        "for i in range(2,10):\n",
        "\n",
        "  \n",
        "  data = train_loader.dataset[i]\n",
        "  preds=torch.sigmoid(model(data)).clone()\n",
        "  errors=robust_fit(data,preds)[0]\n",
        "  a = errors[1][0]\n",
        "  b = errors[0][0]\n",
        "  if not (isinstance (a,str) or isinstance (b,str) ):\n",
        "    if True or b > 0.04 or b < -0.03 or a > 0.04 or a < -0.03  :\n",
        "      plot_classified_line(data,preds,train_tracks[i], train_recon[i] )\n",
        "      plt.title(str(i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPai_ciUV_wt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "624e8934-586b-467a-8bf0-f91b2f872a08"
      },
      "source": [
        "chi_=[]\n",
        "for i in range(len(train_loader.dataset)):\n",
        "\n",
        "  \n",
        "\n",
        "  \n",
        "  data = train_loader.dataset[i]\n",
        "  preds=torch.sigmoid(model(data)).clone()\n",
        "  errors=robust_fit(data,preds)[1]\n",
        "  if errors[1]!='N/A' and errors[0]!='N/A' :\n",
        "\n",
        "    chi_.append(errors[1][3])\n",
        "    chi_.append(errors[0][3])\n"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "oopsie\n",
            "oopsie\n",
            "oopsie\n",
            "oopsie\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUUp2d0isTUM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "49373bb6-9bca-4414-a21d-c480f841e123"
      },
      "source": [
        "supress_=plt.hist(np.array(chi_),bins=np.linspace(1,100,100))"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdAVIGR3ZZ6L",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGWEhVoPY2tg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 930
        },
        "outputId": "219a2bad-0a98-48e9-eb55-88edacdc6f46"
      },
      "source": [
        "error_recon,error_gnn,error_recon_nopull,error_gnn_nopull=[],[],[],[]\n",
        "\n",
        "for iter in range (0,len(test_tracks)):\n",
        "\n",
        "  data = test_loader.dataset[iter]\n",
        "  preds = torch.sigmoid(model(data))\n",
        "  temp = robust_fit(data,preds)\n",
        "  slope = temp[0]\n",
        "\n",
        "  if not (slope[0] == 'N/A' or slope[1] == 'N/A') :\n",
        "\n",
        "    error_gnn.append( ((test_tracks[iter][2]-slope[0][0])/temp[1][0][0] )  )\n",
        "    error_gnn.append( ((test_tracks[iter][4]-slope[1][0])/temp[1][1][0] ))\n",
        "    \n",
        "    error_gnn_nopull.append( ((test_tracks[iter][2]-slope[0][0]) ).numpy() )\n",
        "    error_gnn_nopull.append( ((test_tracks[iter][4]-slope[1][0]) ).numpy() )\n",
        "  \n",
        "  error_recon.append( ((test_tracks[iter][2]-test_recon[iter][0]))/test_recon[iter][2]  )\n",
        "  error_recon.append( ((test_tracks[iter][4]-test_recon[iter][5]))/test_recon[iter][7] )\n",
        "\n",
        "  error_recon_nopull.append( ((test_tracks[iter][2]-test_recon[iter][0])) )\n",
        "  error_recon_nopull.append( ((test_tracks[iter][4]-test_recon[iter][5])))\n",
        "\n",
        "\n",
        "fig=plt.figure(figsize=(15,15))\n",
        "\n",
        "limit_1=0.1\n",
        "limit_2=2\n",
        "error_list = { 'Reconstructed,  True-Predicted ' : error_recon_nopull,'GNN, True-Predicted ' : error_gnn_nopull,\n",
        "              'Reconstructed, (True-Predicted)/error' : error_recon,'GNN, (True-Predicted)/error' : error_gnn}            \n",
        "\n",
        "\n",
        "\n",
        "for i,[title,data] in enumerate(error_list.items()):\n",
        "  ax_list=fig.add_subplot(2,2,i+1)\n",
        "  if i<2:\n",
        "    limit=limit_1\n",
        "  else:\n",
        "    limit=limit_2\n",
        "  supress_=ax_list.hist(np.array(data),bins=np.linspace(-limit,limit,100).tolist())\n",
        "  plt.title(title)\n",
        "\n"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "oopsie\n",
            "oopsie\n",
            "oopsie\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3MAAANeCAYAAAC4e1eSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdebhlVX3u++8rCDYYASmRTgsFYzBRNAgYjSEojaiBGGMwHsUmQa94k9x0gsmJRiViYkSNLUQEjIocTbSiGIIo9tIpoIgcCkShBClpVEAx4O/+McfGyWa3VbupAd/P86yn1hyzG3OuVWusd8wx105VIUmSJEnqyz2WuwKSJEmSpPkzzEmSJElShwxzkiRJktQhw5wkSZIkdcgwJ0mSJEkdMsxJkiRJUocMc9ISSnJGkj9a7npsKJIcn+R17flvJrl4ifZbSXZain1Jkvo0biuSvCvJ/16Cfb4gyRcWez+66zDMaVZJLk/ykyQ3Jrm6fQHfbLnrNZXF/JKeZGXb/saLsf1Z9n3j6PHz0etxY5LnLvK+x6//9xfr9a+qz1fVL8+hPjZ0ktQkOTjJmUluSnJNe/6yJGnzj29t1+6jdXZKUqPpM5L8NMkOo7KnJLl8Dvt/7qg9+klro25vsxb4cCfve6/R/n6c5OIkL1yMfVXVS6vqtXOok522WlKGOc3VM6pqM2BX4DHAEctcn3WyHEFsIVTVZhMP4Lu016M93j+x3CIe38Tr/1hgN+BvJy/Q67mVpF4l+QvgLcA/AQ8CtgZeCjwB2GS06HXA62bZ3E3AvK88VdX7R+3TU4HvTWqzxvXdaL7bn4Pvtf38EvAK4Ngku0xeyDZKd1WGOc1LVV0NnMoQ6gBIsmeSLyW5Icn5SfYazdsyyXuTfC/J9Uk+Opr3x0lWJ7kuyaok247mVZKXJrmkbffto17GnZJ8NskPk/wgyYda+efa6ue3Xro/aL12VyZ5RZKrgfdOdWVn0lCKeyf55yTfafv4QpJ7AxPbv6Ft//Ft+Rcluagd36lJHjLa7j5JvtW28zYg6/8q3KHe63J8myZ5Y5Lvtitt72rHN6uqWgN8EvjV0XYPS3IJcEkre3qS89rr9qUkjxrV4zFJvtp6UD8E3GvysYymd0jy70nWJrk2yduS/ArwLuDx7TW4YS7HlOSvklzV3ocvmudplqQNTpL7A68BXlZVH66qH9fga1X13Kq6ZbT4CcCjkvzWDJt8K/CcJA9bwDoen+SdSU5JchPw25OvXE1us5I8Islp7bvBxUmePZd9tWP/KHA9sEvb7heTHJ3kWuDV69NWZHRbQJs+sLV1P0pyaZL9kxwJ/CbwttZGvW22Y0rygAzfgX6U5Cxgwc6/7h4Mc5qXJNsz9LytbtPbAZ9g6PHbEvhL4CNJVrRV3gfcB3gk8EDg6Lbe3sDrgWcD2wDfAU6atLunA48DHtWW26+Vvxb4b2ALYHvgXwCq6klt/qNbj+CH2vSDWt0eAhw6h8N8I/DrwG+09f4a+Dkwsf3N2/a/nORA4JXAM4EVwOeBD7Zj3Ar4d4arWFsBlzL0li60+R7fUcDDGQL5TsB2wN/NZUcZhuAcAHxtVHwQsAdD4/kY4DjgJcADgHcDq1oDugnwUYb3xJbA/wF+b5r9bAR8nOF9sbLV8aSquoih1/nL7TXYfLZjSrI/w/tyH2Bn4ClzOVZJ2sA9HtgU+Ngclr0Z+AfgyBmWWQMcC/z9+lftDv6w7fd+wIxD5JPcFzgN+ADDd4aDgXdkiittU6x7jyS/C2wOfL0V7wFcxnDF8kgWqK3IMGT1ROCv2v6eBFxeVX/D8D3g5a2NevkcjuntwE8Zvgu9qD2kOTPMaa4+muTHwBXANcCrWvn/Ak6pqlOq6udVdRpwDnBAkm0Ygt9Lq+r6qvqfqvpsW++5wHFV9dXWe3gEw9WWlaN9HlVVN1TVd4HP8Iurgf/DEFy2raqfVtVs90/9HHhVVd1SVT+ZacEk92D4IP3TqlpTVbdV1Zcm9XCOvRR4fVVdVFW3MjSWu7arcwcAF7Ye0/8B3gxcPUtd18V8ji8Mge//q6rrqurHrc4Hz7KPj7arYF8APtvWmfD6tq2ftG2/u6rObOfuBOAWYM/2uCfw5vZe+DBw9jT72x3YFvirqrppptd5Dsf0bOC9VfWNqroJePUsxypJPdgK+EFrewDIL0bJ/CTJkyYt/27gwUmeOsM2Xw88I8kjF7CeH6uqL7bvCD+dZdmnM4Si91bVrVX1NeAjwO/PsM62rX36AcN3k+dV1cSPaX2vqv6lnaOfsnBtxYsZvsOc1o5rTVV9a77H1Doufw/4u9bWfYPhKqo0Z4Y5zdVBVXU/YC/gEQyNCAyh6vdb43FD+0B9IkMP0w7AdVV1/RTb25bhqgsAVXUjcC1DL9mEcfC5GZgYe//XDMMVz0py4RyGza2dQwMyYSuGoX+XznH5hwBvGR37da1u2zEc4xUTC1ZVjacX0HyObwXDldJzR3X+r1ZOkk9m6h9WOaiqNq+qh1TVyyaFxvExPQT4i0nvhx0YzsW2wJp2HiZ8h6ntAHxn/CVlXY+JSa/DDPuUpJ5cC2yV0b1gVfUbbcTCtUz6jtc6JV/bHlOqqrXA2xiGby6U+bR7DwH2mNSGPBd4UJIHZ+ofVvlea5+2rKpdq2o8yme874VsK3Zgft8Tpjymtu+N57Ff6U68GVTzUlWfTXI8w1DEgxg+gN5XVX88edl2ZW7LJJtX1Q2TZn+P4QNuYtn7MgzLWzOHOlwN/HFb74nAp5J8rqpWT7fKpOmbGD7QJ/b9oNG8HzD03j0MOH+W7cBw/EfW6EdIRtvdmeEDf2I64+kFNN/j+wnwyHb/2x03VDVTj+1c9j9xPu40lCfDvRrbJcko0D2YqRvEKxh6kDeeItBNPt4Zjwm4ijue9wdPfyiS1I0vM4x8OJDhSs9cvJfhR0KeOcMy/8QwNPGs9ardL8zYRjGEmglXAJ+tqn2m2dZ8f0l5vO+FbCuuYPp72yYf77TH1K7M3dr2O3FlzzZK8+KVOa2LNwP7JHk08G8MQzL2S7JRkntl+CGL7avqKoYfy3hHki2S3HM07OODwAuT7JpkU4ahDmdW1eWz7TzJ77d792C40bkYhhoCfB946CybOB94ZNv3vRgNpaiqnzPc8/WmJNu2Y3p8q+Patp/x9t8FHDExJCXJ/ZNMDAf5RNvPM1vP6Z8warTyiz91sHK2Y56n2Y7vWODoJA9s9dguyX5Tbmn+jgVemmSPDO6b5GlJ7sfwxeNW4E/ae+GZDMMpp3IWQ8N6VNvGvZJM3G/4fWD7dg/eXI7pZOAFSXZJch9+MURYkrrVOkn/nqGNfVaS+7X7xnYF7jvNOrcyfAa+Ypbt/jPDKJjbZfgBkOMXoOrnAc9Mcp8MP8z14tG8jwMPT/K81k7cM8njMvz41XpZ4LbiPQzfYZ7czvl2SR7R5k3+HjLtMVXVbQz31r+6nY9dgEPW91h192KY07y1YRgnMozxvoKhV/CVDGHnCoYbgifeW89juMftWwz32v1Z28anGH4C+SMMX9ofxuz3bU14HHBmG2axiuH+tsvavFcDJ7ShDFP+AlZV/V+GISSfYvgFxsn3Yv0lw83TZzMMm3wDcI+qupnhBuovtu3vWVX/0eaflORHwDcY7hOkqn7AMM7/KIYhLzsDXxztZweG4RSzXo2cjzkc3ysYfsDmK63OnwJm/ftuc9z3OQxXTd/GELRXAy9o837G0Bv8Aobz+gcMjdhU27kNeAbDDerfBa5sywN8GrgQuDrJD2Y7pqr6JEMHxKfbMp9eiGOVpOVWVf8I/DlD8Pp+e7yb4TPxS9Os9kGGdncmbwFum1S2A3dsw9bV0cDPGOp6AnD7yJZ2H9u+DN8Hvsdwu8UbGH7oZSEsSFtRVWcBL2zH8kOGe8knRhu9BXhWhl+4fuscjunlDFccrwaOZ7h6Ks1Z7nj7iqSlkuRvGe53e/dy10WSpOm0kRDnA49qP+glaQNhmJMkSZKkDjnMUpIkSZI6ZJiTJEmSpA4Z5iRJkiSpQxv035nbaqutauXKlctdDUnSEjj33HN/UFUrZl9SYBspSXcXM7WPG3SYW7lyJeecc85yV0OStASSfGe569AT20hJunuYqX10mKUkSZIkdcgwJ0mSJEkdMsxJkiRJUocMc5IkSZLUIcOcJEmSJHXIMCdJkiRJHTLMSZIkSVKHDHOSJEmS1CHDnCRJkiR1yDAnSZIkSR0yzEmSJElShwxzkiRJktQhw5wkSZIkdcgwJ0mSJEkdMsxJkiRJUocMc5IkSZLUoY2XuwKSfmHl4Z+4/fnlRz1tGWsiSdKGY9w+gm2kNMErc5IkSZLUIcOcJEnrIclGSb6W5ONtesckZyZZneRDSTZp5Zu26dVt/srRNo5o5Rcn2W95jkSS1BvDnCRJ6+dPgYtG028Ajq6qnYDrgRe38hcD17fyo9tyJNkFOBh4JLA/8I4kGy1R3SVJHTPMSZK0jpJsDzwN+Nc2HWBv4MNtkROAg9rzA9s0bf6T2/IHAidV1S1V9W1gNbD70hyBJKlncw5zDiORJOlO3gz8NfDzNv0A4IaqurVNXwls155vB1wB0Ob/sC1/e/kU69xBkkOTnJPknLVr1y7kcUiSOjSfK3MOI5EkqUnydOCaqjp3qfZZVcdU1W5VtduKFSuWareSpA3UnMKcw0gkSbqTJwC/k+Ry4CSGdvEtwOZJJv70z/bAmvZ8DbADQJt/f+DacfkU60iSNK25XplbsmEkDiGRJPWgqo6oqu2raiXDyJNPV9Vzgc8Az2qLHQJ8rD1f1aZp8z9dVdXKD263KewI7AyctUSHIUnq2KxhbqmHkTiERJLUuVcAf55kNUNn5nta+XuAB7TyPwcOB6iqC4GTgW8C/wUcVlW3LXmtJUnd2Xj2RW4fRnIAcC/glxgNI2lX36YaRnKlw0gkSXcHVXUGcEZ7fhlT3EZQVT8Ffn+a9Y8Ejly8GkqS7opmvTLnMBJJkiRJ2vDM5crcdF4BnJTkdcDXuOMwkve1YSTXMQRAqurCJBPDSG7FYSSSJEmStM7mFeYcRiJJkiRJG4b5/J05SZIkSdIGwjAnSZIkSR0yzEmSJElShwxzkiRJktQhw5wkSZIkdcgwJ0mSJEkdMsxJkiRJUocMc5IkSZLUIcOcJEmSJHXIMCdJkiRJHTLMSZIkSVKHDHOSJEmS1CHDnCRJkiR1yDAnSZIkSR0yzEmSJElShwxzkiRJktQhw5wkSZIkdcgwJ0mSJEkdMsxJkiRJUocMc5IkSZLUIcOcJEmSJHXIMCdJkiRJHTLMSZIkSVKHDHOSJEmS1CHDnCRJkiR1yDAnSZIkSR0yzEmSJElShwxzkiRJktQhw5wkSZIkdcgwJ0mSJEkdMsxJkiRJUocMc5IkraMk90pyVpLzk1yY5O9b+fFJvp3kvPbYtZUnyVuTrE5yQZLHjrZ1SJJL2uOQ5TomSVI/Nl7uCkiS1LFbgL2r6sYk9wS+kOSTbd5fVdWHJy3/VGDn9tgDeCewR5ItgVcBuwEFnJtkVVVdvyRHIUnqklfmJElaRzW4sU3esz1qhlUOBE5s630F2DzJNsB+wGlVdV0LcKcB+y9m3SVJ/Zs1zDmERJKk6SXZKMl5wDUMgezMNuvI1g4enWTTVrYdcMVo9Stb2XTlk/d1aJJzkpyzdu3aBT8WSVJf5nJlbmIIyaOBXYH9k+zZ5v1VVe3aHue1svEQkkMZhpAwGkKyB7A78KokWyzcoUiStPSq6raq2hXYHtg9ya8CRwCPAB4HbAm8YoH2dUxV7VZVu61YsWIhNilJ6tisYc4hJJIkza6qbgA+A+xfVVe1dvAW4L0MnZgAa4AdRqtt38qmK5ckaVpzumfOISSSJN1ZkhVJNm/P7w3sA3yrdWKSJMBBwDfaKquA57dbEvYEflhVVwGnAvsm2aKNWtm3lUmSNK05hTmHkEiSNKVtgM8kuQA4m6HD8+PA+5N8Hfg6sBXwurb8KcBlwGrgWOBlAFV1HfDato2zgde0MkmSpjWvP01QVTckmRhC8sZWfEuS9wJ/2aZnGkKy16TyM9ahzpIkbRCq6gLgMVOU7z3N8gUcNs2844DjFrSCkqS7tLn8mqVDSCRJkiRpAzOXK3PbACck2Ygh/J1cVR9P8ukkK4AA5wEvbcufAhzAMITkZuCFMAwhSTIxhAQcQiJJkiRJ62zWMOcQEkmSJEna8MzpB1AkSZIkSRsWw5wkSZIkdcgwJ0mSJEkdMsxJkiRJUocMc5IkSZLUIcOcJEmSJHXIMCdJkiRJHTLMSZIkSVKHDHOSJEmS1CHDnCRJkiR1yDAnSZIkSR0yzEmSJElShwxzkiRJktQhw5wkSZIkdcgwJ0mSJEkdMsxJkiRJUocMc5IkSZLUIcOcJEmSJHXIMCdJkiRJHTLMSZIkSVKHDHOSJEmS1CHDnCRJkiR1yDAnSZIkSR0yzEmSJElShwxzkiRJktQhw5wkSZIkdcgwJ0mSJEkdMsxJkiRJUocMc5IkSZLUIcOcJEmSJHXIMCdJkiRJHTLMSZIkSVKHDHOSJK2jJPdKclaS85NcmOTvW/mOSc5MsjrJh5Js0so3bdOr2/yVo20d0covTrLf8hyRJKknhjlJktbdLcDeVfVoYFdg/yR7Am8Ajq6qnYDrgRe35V8MXN/Kj27LkWQX4GDgkcD+wDuSbLSkRyJJ6s6sYc5eR0mSplaDG9vkPdujgL2BD7fyE4CD2vMD2zRt/pOTpJWfVFW3VNW3gdXA7ktwCJKkjs3lypy9jpIkTSPJRknOA64BTgMuBW6oqlvbIlcC27Xn2wFXALT5PwQeMC6fYp3xvg5Nck6Sc9auXbsYhyNJ6sisYc5eR0mSpldVt1XVrsD2DO3aIxZxX8dU1W5VtduKFSsWazeSpE7M6Z45ex0lSZpZVd0AfAZ4PLB5ko3brO2BNe35GmAHgDb//sC14/Ip1pEkaUpzCnP2OkqSdGdJViTZvD2/N7APcBFDqHtWW+wQ4GPt+ao2TZv/6aqqVn5wu+98R2Bn4KylOQpJUq82nn2RX6iqG5LcodexXX2bqtfxSnsdJUl3cdsAJ7R7wO8BnFxVH0/yTeCkJK8Dvga8py3/HuB9SVYD1zHcS05VXZjkZOCbwK3AYVV12xIfiySpM7OGuSQrgP9pQW6i1/EN/KLX8SSm7nX8MqNexySrgA8keROwLfY6SpI6V1UXAI+ZovwyprgvvKp+Cvz+NNs6EjhyoesoSbrrmsuVOXsdJUmSJGkDM2uYs9dRkiRJkjY8c/oBFEmSJEnShsUwJ0mSJEkdMsxJkiRJUocMc5IkSZLUIcOcJEmSJHXIMCdJkiRJHTLMSZIkSVKHDHOSJEmS1CHDnCRJkiR1yDAnSZIkSR0yzEmSJElShwxzkiRJktQhw5wkSZIkdcgwJ0mSJEkdMsxJkiRJUocMc5IkSZLUIcOcJEmSJHXIMCdJkiRJHTLMSZIkSVKHDHOSJEmS1CHDnCRJkiR1yDAnSZIkSR0yzEmSJElShwxzkiRJktQhw5wkSZIkdcgwJ0mSJEkdMsxJkiRJUocMc5IkSZLUIcOcJEmSJHXIMCdJkiRJHTLMSZIkSVKHDHOSJEmS1CHDnCRJ6yDJDkk+k+SbSS5M8qet/NVJ1iQ5rz0OGK1zRJLVSS5Ost+ofP9WtjrJ4ctxPJKk/my83BWQJKlTtwJ/UVVfTXI/4Nwkp7V5R1fVG8cLJ9kFOBh4JLAt8KkkD2+z3w7sA1wJnJ1kVVV9c0mOQpLUrVmvzNnzKEnSnVXVVVX11fb8x8BFwHYzrHIgcFJV3VJV3wZWA7u3x+qquqyqfgac1JaVJGlGcxlmOdHzuAuwJ3BY612Eoedx1/Y4Be7U87g/8I4kGyXZiKHn8anALsBzRtuRJKlbSVYCjwHObEUvT3JBkuOSbNHKtgOuGK12ZSubrnyq/Rya5Jwk56xdu3YBj0CS1KNZw5w9j5IkTS/JZsBHgD+rqh8B7wQeBuwKXAX880Ltq6qOqardqmq3FStWLNRmJUmdmtcPoCxFz6O9jpKkXiS5J0OQe39V/TtAVX2/qm6rqp8DxzJ0ZgKsAXYYrb59K5uuXJKkGc05zC1Vz6O9jpKkHiQJ8B7goqp606h8m9Fivwt8oz1fBRycZNMkOwI7A2cBZwM7J9kxySYMtyqsWopjkCT1bU6/Zjldz+No/rHAx9vkTD2M9jxKku4qngA8D/h6kvNa2SsZ7gnfFSjgcuAlAFV1YZKTgW8y3I9+WFXdBpDk5cCpwEbAcVV14VIeiCSpT7OGuZl6HqvqqjY5uefxA0nexPDTyxM9j6H1PDKEuIOBP1yoA5EkaSlV1RcY2rbJTplhnSOBI6coP2Wm9SRJmspcrszZ8yhJkiRJG5hZw5w9j5IkSZK04ZnXr1lKkiRJkjYMhjlJkiRJ6pBhTpIkSZI6ZJiTJEmSpA4Z5iRJkiSpQ4Y5SZIkSeqQYU6SJEmSOmSYkyRJkqQOGeYkSZIkqUOGOUmSJEnqkGFOkiRJkjpkmJMkSZKkDhnmJEmSJKlDhjlJkiRJ6pBhTpIkSZI6ZJiTJEmSpA4Z5iRJkiSpQ4Y5SZIkSeqQYU6SJEmSOmSYkyRJkqQOGeYkSZIkqUOGOUmSJEnqkGFOkiRJkjpkmJMkSZKkDhnmJEmSJKlDhjlJkiRJ6pBhTpIkSZI6ZJiTJEmSpA4Z5iRJkiSpQ4Y5SZIkSeqQYU6SJEmSOmSYkyRJkqQOGeYkSZIkqUOGOUmS1lGSHZJ8Jsk3k1yY5E9b+ZZJTktySft3i1aeJG9NsjrJBUkeO9rWIW35S5IcslzHJEnqx6xhzoZKkqRp3Qr8RVXtAuwJHJZkF+Bw4PSq2hk4vU0DPBXYuT0OBd4JQ5sKvArYA9gdeNVEuypJ0nTmcmXOhkqSpClU1VVV9dX2/MfARcB2wIHACW2xE4CD2vMDgRNr8BVg8yTbAPsBp1XVdVV1PXAasP8SHookqUOzhjkbKkmSZpdkJfAY4Exg66q6qs26Gti6Pd8OuGK02pWtbLryyfs4NMk5Sc5Zu3btgtZfktSfed0zZ0MlSdKdJdkM+AjwZ1X1o/G8qiqgFmI/VXVMVe1WVbutWLFiITYpSerYnMOcDZUkSXeW5J4M7eP7q+rfW/H326gU2r/XtPI1wA6j1bdvZdOVS5I0rTmFORsqSZLuLEmA9wAXVdWbRrNWARM/9HUI8LFR+fPbj4XtCfywjXI5Fdg3yRbtfvJ9W5kkSdOay69Z2lBJkjS1JwDPA/ZOcl57HAAcBeyT5BLgKW0a4BTgMmA1cCzwMoCqug54LXB2e7ymlUmSNK2N57DMREP19STntbJXMjRMJyd5MfAd4Nlt3inAAQwN1c3AC2FoqJJMNFRgQyVJ6lxVfQHINLOfPMXyBRw2zbaOA45buNpJku7qZg1zNlSSJEmStOGZ169ZSpIkSZI2DIY5SZIkSeqQYU6SJEmSOmSYkyRJkqQOGeYkSZIkqUOGOUmSJEnqkGFOkiRJkjpkmJMkSZKkDhnmJEmSJKlDhjlJkiRJ6pBhTpIkSZI6ZJiTJEmSpA4Z5iRJkiSpQ4Y5SZIkSeqQYU6SJEmSOmSYkyRJkqQOGeYkSZIkqUOGOUmSJEnqkGFOkiRJkjpkmJMkSZKkDhnmJEmSJKlDhjlJkiRJ6pBhTpIkSZI6ZJiTJEmSpA4Z5iRJkiSpQ4Y5SZIkSeqQYU6SJEmSOmSYkyRJkqQOGeYkSZIkqUOGOUmSJEnqkGFOkiRJkjpkmJMkSZKkDhnmJEmSJKlDhjlJktZRkuOSXJPkG6OyVydZk+S89jhgNO+IJKuTXJxkv1H5/q1sdZLDl/o4JEl9mjXM2VBJkjSt44H9pyg/uqp2bY9TAJLsAhwMPLKt844kGyXZCHg78FRgF+A5bVlJkmY0lytzx2NDJUnSnVTV54Dr5rj4gcBJVXVLVX0bWA3s3h6rq+qyqvoZcFJbVpKkGc0a5myoJEmat5cnuaCNbtmilW0HXDFa5spWNl35nSQ5NMk5Sc5Zu3btYtRbktSR9blnblEaKkmSOvdO4GHArsBVwD8v1Iar6piq2q2qdluxYsVCbVaS1Kl1DXOL1lDZ6yhJ6llVfb+qbquqnwPHMoxOAVgD7DBadPtWNl25JEkzWqcwt5gNlb2OkqSeJdlmNPm7wMQPiK0CDk6yaZIdgZ2Bs4CzgZ2T7JhkE4Z7z1ctZZ0lSX3aeF1WSrJNVV3VJic3VB9I8iZgW37RUIXWUDGEuIOBP1yfikuStNySfBDYC9gqyZXAq4C9kuwKFHA58BKAqrowycnAN4FbgcOq6ra2nZcDpwIbAcdV1YVLfCiSpA7NGuZsqCRJmlpVPWeK4vfMsPyRwJFTlJ8CnLKAVZMk3Q3MGuZsqCRJkiRpw7M+v2YpSZIkSVomhjlJkiRJ6pBhTpIkSZI6ZJiTJEmSpA4Z5iRJkiSpQ4Y5SZIkSeqQYU6SJEmSOmSYkyRJkqQOGeYkSZIkqUOGOUmSJEnqkGFOkiRJkjpkmJMkSZKkDhnmJEmSJKlDhjlJkiRJ6pBhTpIkSZI6ZJiTJEmSpA4Z5iRJkiSpQ4Y5SZIkSeqQYU6SJEmSOmSYkyRJkqQOGeYkSZIkqUOGOUmSJEnqkGFOkiRJkjpkmJMkSZKkDhnmJEmSJKlDhjlJkiRJ6pBhTpIkSZI6ZJiTJEmSpA4Z5iRJkiSpQ4Y5SZIkSeqQYU6SJEmSOmSYkyRJkqQOGeYkSZIkqUOGOUmSJEnqkGFOkqR1lOS4JNck+caobMskpyW5pP27RStPkrcmWZ3kgiSPHa1zSFv+kiSHLMexSJL6M2uYs6GSJGlaxwP7Tyo7HDi9qnYGTm/TAE8Fdm6PQ4F3wtCmAq8C9gB2B1410a5KkjSTuVyZOx4bKkmS7qSqPgdcN6n4QOCE9vwE4KBR+Yk1+AqweZJtgP2A06rquqq6HjiNO7e7kiTdyaxhzoZKkqR52bqqrmrPrwa2bs+3A64YLXdlK5uu/E6SHJrknCTnrF27dmFrLUnqzrreM2dDJUnSLKqqgFrA7R1TVbtV1W4rVqxYqM1Kkjq13j+AYkMlSdIdfL+NSqH9e0wLJNQAACAASURBVE0rXwPsMFpu+1Y2XbkkSTNa1zBnQyVJ0tRWARM/9HUI8LFR+fPbj4XtCfywjXI5Fdg3yRbtfvJ9W5kkSTNa1zBnQyVJuttL8kHgy8AvJ7kyyYuBo4B9klwCPKVNA5wCXAasBo4FXgZQVdcBrwXObo/XtDJJkma08WwLtIZqL2CrJFcy/CrlUcDJrdH6DvDstvgpwAEMDdXNwAthaKiSTDRUYEMlSboLqKrnTDPryVMsW8Bh02znOOC4BayaJOluYNYwZ0MlSZIkSRue9f4BFEmSJEnS0jPMSZIkSVKHDHOSJEmS1CHDnCRJkiR1yDAnSZIkSR0yzEmSJElShwxzkiRJktQhw5wkSZIkdcgwJ0mSJEkdMsxJkiRJUocMc5IkSZLUIcOcJEmSJHXIMCdJkiRJHTLMSZIkSVKHDHOSJEmS1CHDnCRJkiR1yDAnSZIkSR0yzEmSJElShwxzkiRJktQhw5wkSZIkdcgwJ0mSJEkdMsxJkiRJUocMc5IkSZLUIcOcJEmSJHXIMCdJkiRJHTLMSZIkSVKHDHOSJEmS1CHDnCRJkiR1yDAnSZIkSR0yzEmSJElShwxzkiRJktQhw5wkSZIkdcgwJ0mSJEkdMsxJkrQIklye5OtJzktyTivbMslpSS5p/27RypPkrUlWJ7kgyWOXt/aSpB6sV5izoZIkaUa/XVW7VtVubfpw4PSq2hk4vU0DPBXYuT0OBd655DWVJHVnIa7M2VBJkjQ3BwIntOcnAAeNyk+swVeAzZNssxwVlCT1YzGGWdpQSZIEBfx3knOTHNrKtq6qq9rzq4Gt2/PtgCtG617ZyiRJmtbG67n+RENVwLur6hjm31BdNSqjNXiHAjz4wQ9ez+pJkrRsnlhVa5I8EDgtybfGM6uqWvs5Z7aRkqSx9b0y98SqeizDEMrDkjxpPLOqiiHwzVlVHVNVu1XVbitWrFjP6kmStDyqak379xrgP4Ddge9PjEpp/17TFl8D7DBafftWNnmbtpGSpNutV5hbjIZKkqTeJblvkvtNPAf2Bb4BrAIOaYsdAnysPV8FPL/9WNiewA9Ho1wkSZrSOoc5GypJkqa1NfCFJOcDZwGfqKr/Ao4C9klyCfCUNg1wCnAZsBo4FnjZ0ldZktSb9blnbmvgP5JMbOcDVfVfSc4GTk7yYuA7wLPb8qcABzA0VDcDL1yPfUuStMGqqsuAR09Rfi3w5CnKCzhsCaomSboLWecwZ0MlSZIkSctnMf40gSRJkiRpkRnmJEmSJKlDhjlJkiRJ6pBhTpIkSZI6ZJiTJEmSpA6tz58mkCRJkhbFysM/sdxVkDZ4hjlpGdlQSZIkaV05zFKSJEmSOuSVOUmSJHVlPLLl8qOetow1kZaXV+YkSZIkqUNemZM2UJPvp7PnUZIkSWNemZMkSZKkDhnmJEmSJKlDhjlJkiRJ6pBhTpIkSZI6ZJiTJEmSpA4Z5iRJkiSpQ4Y5SZIkSeqQYU6SJEmSOmSYkyRJkqQOGeYkSZIkqUOGOUmSJEnqkGFOkiRJkjpkmJMkSZKkDhnmJEmSJKlDhjlJkiRJ6pBhTpIkSZI6ZJiTJEmSpA4Z5iRJkiSpQ4Y5SZIkSeqQYU6SJEmSOrTxcldA0tysPPwTtz+//KinLWNNJElaeON2bn3Ws43U3YlhTlpi69pYSZIkSWMOs5QkSZKkDi15mEuyf5KLk6xOcvhS71+SpA2R7aMkab6WdJhlko2AtwP7AFcCZydZVVXfXMp6SL3z/gDprsX2UZK0Lpb6nrndgdVVdRlAkpOAAwEbK91leY+cpDmwfdTd0mK0kf5gmO5OljrMbQdcMZq+EthjvECSQ4FD2+SNSS5egP1uBfxgAbazFKzr4uiprjDP+uYNi1iT2fV0bq3r4lmI+j5kISrSqVnbR1iUNvLu+D5bKtZ1cdg+Lp6e6nt3q+u07eMG92uWVXUMcMxCbjPJOVW120Juc7FY18XRU12hr/pa18XRU12hv/r2aqHbyN5et57qa10Xh3VdPD3V17r+wlL/AMoaYIfR9PatTJKkuzPbR0nSvC11mDsb2DnJjkk2AQ4GVi1xHSRJ2tDYPkqS5m1Jh1lW1a1JXg6cCmwEHFdVFy7Brhd02OYis66Lo6e6Ql/1ta6Lo6e6Qn/13aDYPs5ZT/W1rovDui6enuprXZtU1WJuX5IkSZK0CJb8j4ZLkiRJktafYU6SJEmSOtRtmEuyZZLTklzS/t1imuX+K8kNST4+qXzHJGcmWZ3kQ+2Gc5Js2qZXt/krl7i+h7RlLklySCu7X5LzRo8fJHlzm/eCJGtH8/5oOevays9IcvGoTg9s5Qt+btfzvN4nySeSfCvJhUmOGi2/YOc1yf7tfKxOcvgU86c9L0mOaOUXJ9lvrttc6rom2SfJuUm+3v7de7TOlO+HZa7vyiQ/GdXpXaN1fr0dx+okb02SZa7rcyf9//95kl3bvEU5t3Oo65OSfDXJrUmeNWnedJ8Li3JeNbV5fDYuexs5j7raPi5hfWMbuWB1zTK0ketRV9vH9a/v0raRVdXlA/hH4PD2/HDgDdMs92TgGcDHJ5WfDBzcnr8L+H/a85cB72rPDwY+tFT1BbYELmv/btGebzHFcucCT2rPXwC8banP7Ux1Bc4AdptinQU/t+tTV+A+wG+3ZTYBPg88dSHPK8MPGVwKPLTt43xgl7mcF2CXtvymwI5tOxvNZZvLUNfHANu2578KrBmtM+X7YZnruxL4xjTbPQvYEwjwyYn3xHLVddIyvwZcupjndo51XQk8CjgReNZs/9cW67z6mPF17KaNnEtdZ3pvTVrO9nGB6ott5ELWdUnbyPWs60psH9e3vitZwjay2ytzwIHACe35CcBBUy1UVacDPx6XtbS7N/DhKdYfb/fDwJMXqOdhLvXdDzitqq6rquuB04D9J9X94cADGT5UF8uC1HWW7S7UuV3nulbVzVX1GYCq+hnwVYa/7bSQdgdWV9VlbR8ntTpPdwzj83IgcFJV3VJV3wZWt+3NZZtLWteq+lpVfa+VXwjcO8mmC1CnRanvdBtMsg3wS1X1lRo+XU9kms+WZarrc9q6i2nWulbV5VV1AfDzSetO+X9tEc+rptdTG2n7uAF+97CNXLi6LkMbafu4eDa4NrLnMLd1VV3Vnl8NbD2PdR8A3FBVt7bpK4Ht2vPtgCtg+Klo4Idt+fU1l/revu8p6jVhokdi/DOkv5fkgiQfTrID628h6vredln7f4/+wy3GuV2Q85pkc4be6dNHxQtxXufymk53XqZbdy7bXOq6jv0e8NWqumVUNtX7Ybnru2OSryX5bJLfHC1/5SzbXI66TvgD4IOTyhb63K7P+2um9+xinFdNr6c20vZxA//uYRu53nUdW4o20vZxsFzfPea77nqd2yX9O3PzleRTwIOmmPU344mqqiTL/jcWlqi+BwPPG03/J/DBqrolyUsYei72nnLNpavrc6tqTZL7AR9p9T1xntu43WKf1yQbM3wAvLWqLmvF63Re7+6SPBJ4A7DvqHhB3w8L5CrgwVV1bZJfBz7a6r7BSrIHcHNVfWNUvCGeWy2RntpI28fbLfj/WdvIfnTSRto+dmaDDnNV9ZTp5iX5fpJtquqqdnnymnls+lpg8yQbt4S/PbCmzVsD7ABc2T7A7t+WX4r6rgH2Gk1vzzDmd2IbjwY2rqpzR/sc1+1fGcbHL2tdq2pN+/fHST7AcEn6RNbx3C72eWX4Y46XVNWbR/tcp/M6zb7HPZbj99rkZSafl5nWnW2bS11XkmwP/Afw/Kq6dGKFGd4Py1bf1nN/S6vXuUkuBR7elh8PI9ogzm1zMJN6HRfp3M6lrjOtu9ekdc9g8c7r3VpPbaTt4+K0j4td38Y2cv3rutRtpO3j8n73mGndvSatewbreW57Hma5Cpj4FZhDgI/NdcX2Rv0MMPELM+P1x9t9FvDpSUM21tVc6nsqsG+SLTL84tS+rWzCc5j0Zm0fzhN+B7hoOeuaZOMkW7W63RN4OjDRU7IY53a9zmuS1zF8KPzZeIUFPK9nAztn+GW4TRg+cFbNcAzj87IKODjDrzjtCOzMcIPsXLa5pHVtQ3A+wXCj/RcnFp7l/bCc9V2RZKNWr4cynNvL2nCkHyXZsw3JeD7z+GxZjLq2Ot4DeDaj+wEW8dyuz/tryv9ri3heNb2e2kjbxw30u4dt5MLUdRnaSNvH5f3uMZ3FaSNrgX/lZakeDGNlTwcuAT4FbNnKdwP+dbTc54G1wE8YxqDu18ofyvCffjXwf4BNW/m92vTqNv+hS1zfF7V9rwZeOGkblwGPmFT2eoabac9naHwfsZx1Be7L8GtiF7R6vQXYaLHO7XrWdXugGBqh89rjjxb6vAIHAP+X4deP/qaVvQb4ndnOC8MwmUuBixn9stFU21yg9+k61RX4W+Cm0Xk8j+GHCKZ9PyxzfX+v1ec8hpv6nzHa5m4MH/qXAm8Dspx1bfP2Ar4yaXuLdm7nUNfHMXye3sTQO3rhTP/XFvO8+pj2NeymjZxHXW0fl7a+tpELVFeWoY1cj7raPq5/fZe0jUzbgCRJkiSpIz0Ps5QkSZKkuy3DnCRJkiR1yDAnSZIkSR0yzEmSJElShwxzkiRJktQhw5wkSZIkdcgwJ0mSJEkdMsxJkiRJUocMc5IkSZLUIcOcJEmSJHXIMCdJkiRJHTLMSZIkSVKHDHOSJEmS1CHDnCRJkiR1yDAnSZIkSR0yzEmSJElShwxzkiRJktQhw5wkSZIkdcgwJ0mSJEkdMsxJkiRJUocMc5IkSZLUIcOcJEmSJHXIMCdJkiRJHTLMSZIkSVKHDHOSJEmS1CHDnCRJkiR1yDAnSZIkSR0yzEmSJElShwxzkiRJktQhw5wkSZIkdcgwJ0mSJEkdMsxJkiRJUocMc5IkSZLUIcOcJEmSJHXIMCdJkiRJHTLMSZIkSVKHDHOSJEmS1CHDnCRJkiR1yDAnSZIkSR0yzEmSJElShwxzkiRJktQhw5wkSZIkdcgwJ81BkjOS/NE8ln9JkjcvZp2WW5LLkzylPX9lkn9dgn3uleTK0fRZSR652PuVpLuiJJsm+WaSbZa7LoslyQuSfGE0fWOShy7Bfm//3pDkGUk+tNj71N2TYe4urH3Z/kn74Lo6yfFJNlvuek0lSSXZaZG2vbJtf+PF2P4U+9sE+Fvgn5L8Zjv/Nya5qdXjxtHjwYtYj5WT9nd5ksMXY19V9Q9VNWvYbe/B1y3grt8IvGaK/RyR5B8WcD+StGCSHJzkzNYuXNOevyxJ2vzj2+f37qN1dkpSo+kzkvw0yQ6jsqckuXweVTkU+FxVXZXkk6P24n+S/Gw0/a4FOOxpteOd2N91SU5L8ojF2FdVbVZVl81SnwX93lBV/wk8MsmjJu1nkyQ/2FC/m6kPhrm7vmdU1WbArsBjgCOWuT7rZKmC2AI5EPhWVa2pqs+3hmMzYOIK0uYTZVX13YmVFvEYN2/7fw7wd0n2n7xAZ+d3bBXw20keNKn8acAp89nQVOdgvuel4/MoaYkk+QvgLcA/AQ8CtgZeCjwB2GS06HXAbJ1fNwH/ez2q81LgfQBV9dRRe/V+4B9HbdVLR/VfrM+5f2z73h64Bjh+8gIZ9Prd9YMM4XnsScB5VXXjfDY0TXu10Ty3Ma/lteHq9T+E5qmqrgZOZQh1ACTZM8mXktyQ5Pwke43mbZnkvUm+l+T6JB8dzfvjJKtb79mqJNuO5lWSlya5pG337aOexp2SfDbJD1tP1Ida+efa6ue3Xrk/SBtOl+QVSa4G3ptJQyVG+9upPb93kn9O8p22jy8kuTcwsf0b2vYf35Z/UZKL2vGdmuQho+3uk+RbbTtvAzKP0/1U4LOzLZTk1Uk+nOTfkvwIeMHkK1e587DCbZN8JMnaJN9O8idzrVRVfRm4EPjVac7vPZIcnuTSJNcmOTnJlqN9P6+d22uT/M0Ux/Jvo+knjt5bV7TX7lDgucBft9fhP2c7pvaaHt9eo28Cj5t0TD8FzgX2G62zBfBw4Mtt+ulJzmt1+VJGPaMZrla+IskFwE3tPVpJXpzku8Cn23n523bs1yQ5Mcn92/orJy8/19dD0t1P++x4DfCyqvpwVf24Bl+rqudW1S2jxU8AHpXkt2bY5FuB5yR52DrU5cHAQ4Ez57BsJTksySXAJZniylUm3Y4wUxs7k6q6GfgA8Kuj7R6Z5IvAzcBDkzwiw9W765JcnOTZo/0+IMN3kx8lOQu4w7lZxu8NZzB0NI4dQOt4THL/JO9JclWSNUlelxa4Whv6xSRHJ7kWeHVrG9+Z5JQkNzF0bP5KO183JLkwye+M6nen5efyemjDZ5i7m0iyPUPIWN2mtwM+wdDrtyXwl8BHkqxoq7wPuA/D1aQHAke39fYGXg88G9gG+A5w0qTdPZ3hS/ej2nITX7RfC/w3sAVDz9u/AFTVk9r8R7cewIlx5Q9qdXsId+7NmsobgV8HfqOt99fAzxl6vuAXV8S+nORA4JXAM4EVwOcZes1IshXw7wxDJbcCLmXoMZ2rXwMunuOyBwIfBjZn6AmdVobeyP8Ezge2A54M/FmS/WZar62bJE9geD2/1oonn9//FzgI+C1gW+B64O1t/V2AdwLPa/MewPAaTrWvhwCfZHh9VzB0IJxXVcdwx97eZ8zhmF7F0BA/jOF9dMgUu7wIePRoej/g9Kq6LcljgOOAl7Q6vxtYlWTT0fLPYWhgNwdubWW/BfxK29YL2uO3Gb74bAa8bVIdxstL0nQeD2wKfGwOy94M/ANw5AzLrAGOBf5+Herya8BlVXXrrEsODgL2AHaZbcGZ2tg5rLsZQ8ff10bFz2Nop+4HrAVOYwh8DwQOBt7R2ikY2q2fMnxHeVF7TGcpvzdcBKxM8kujsgMYvovBcCXyVmAnhpFU+wLj2xf2AC5juJI78Z74w/b8fgyh/D8Zvmc9kKFNf3+SXx5tY7z8HTrH1bGq8nEXfQCXAzcCPwYKOJ3hgwngFcD7Ji1/KsOX5W0YPsy2mGKb72H4Mj4xvRnwP8DKNl3AE0fzTwYOb89PBI4Btp9iuwXsNJreC/gZcK9R2QuAL0y1HkPHxE8YAuHkba9sy208Kvsk8OLR9D0YGs6HAM8HvjKaF+BK4I/meN4vAfafrR7AqxnuVRgvczzwuknn4cr2fA/gu5OWPwJ47zT1mNjfDQzB7CLgT2Y4vxcBTx5Nb9Ne242BvwNOGs27b1v/KaNj+bdRnf5jmjpNPr4Zj4mh4dp/NO/QifMxKjsSOG40/T7gee35O4HXTlr+YuC3Rv9HXjTFOXvoqOx0hl70ielfHp2XOy3vw4cPH9M9gP8FXD2p7Evtc/onwJNa2fEMna2bAt9l6IzdCajRemcwfNlfAfyQobPuKcDlc6zLcxm1dZPmTf6sLmDv0fTEZ9/Gk+vTnk/bxs6wv5+283A1wxD6h422+5rRsn8AfH7S+v9/e/cfbeld14f+/WmGGEE0CZkbY34w0aZC2nVVOkYU62URvcUESdpCFtZqpLlOXUUF9V4Z6V3F9lbv0Fo1rpYfWQQZXKwEGrCJhlohQlntLaMTDCQQlBgmZtJJMihBlHuF6Pf+8TwTds6cOXNm5jx77+85r9daZ529n/3s5/mcZ++zv/vzfD/f7/OmDCf/Ths/n58189jPZea7Qxb0vSHJU8ZtXjTe/7ok9423z03yF0m+fGb9703y/vH2D+botvKtSd42c//vjMfur80suynJz6y2vp/N86NnbvO7urX29Axf3p+V4YxRMnz4vHTsin+sqh5L8u0ZvsBfmORPWmufWWV7X5OhNy5J0oY67z/O0KtyxMMztz+fIeFLhjNeleR3xu7/tc6WJcnhNpTRrcc5Sc7IcDZsPZ6Z5PqZv/1PxtjOz/A3PnhkxTZ8Cj646lZW95kMZ73W40S2+8wkX7PiNXtNhkbgyAxdq02sck5r7azW2rNba788s3zl8X1mkl+b2fa9Sf5y3P7KY/LnGV731VyYE3sdjvk3rdxvZt57M56e4QvAkd7L70rymzPb/8kV279w3O4Rq70Gs8ue9J4fb2+bifFY2wBY6Y+TnDNbntha+7bW2pnjY0/6XtaGssv/a/xZVWvtcIZqgaMmgzqOE2mrkhNvr1ZtY2uY/Xi1iVV+vrV2Zmvtq1trL26tzbYjD67Y9res+Fz/vgzVJtszfD4fr91I5v+94cixfmz8fUWGBPHItp+S5NDM9t+UoYftiPW0VQ+21v5qZtkDefL3M23VJmSw/hbRWvsvVfXWDCUFV2f4h/7V1toPrVy3himKz66qM1trj614+H9k+NA5su7TMpSvPbSOGB5O8kPj8749yfuq6oOttfuO9ZQV9/88Q+nnkX3PTnrx6Qxn9b4uQ8neWttJhr//Z1trR5U2VtUlGb7wH7lfs/fX4aMZxmytx5p/Y4bG6YgHk3yqtXbJqhsaBo4/oap2nOC+H8zQS/XfVq5YVYcylBEeuf/UDK/7ah5MctkxHlttn8f8m5IcynDsPzbeX232z2cnOTJe75uTPDB+uTmy/Z9tra1VprTa+2N22ZPe82MMjyd5JF8qNV1tGwAr/fcMPTBXJXnXOp/zKxmqaf7+Guv8mwyVDL9zArF8NMnFVbWtra/UcvZz7s/H309N8qfj7ZXt1aptbIaeyBOdbXh23w8m+S+tte9audI4xuzxDO3GJ8bFx5o1et7fG56dodf0yPG6IsOYxyPb/osMJ1+P9Vqsp626sKr+2kxCd1GSPzjONuicnrmt5ZeSfFdVfUOGL7/fU1V/t6pOq6ozapgU44LW2qEMZ4teX1VnVdVTqupI/fhNSV5eVd84jjv6uST7WmsHjrfzqnrpOHYvGc4ItgzlnMnwxfh41335SIapfb+xqs7IUNqXJBk/uN6S5BdqmFDjtKr61jHGw+N+Zrf/xiQ/XeM1ymoYePzS8bHbx/38/fHs6Y9lppGqLw383nGMON+TYQzVybgryRU1TEDz1UleNfPY7yT5XA0Tdnz5+Df+rar65tU3dcLemORnxzFvqart4xiBZBjX96IaJjY5PcMZ4GN9frw9yXdW1TVVta2GwehHJt5Z+Tof7296Z4bX6azxvfOjszsa3wd/O8P4ieTJ4w+SYSzJD1fVt9TgaVV1ZVWdyNnom5L8eFVdPI7l+Lkk71jnlx+AJ4wnSP9Fhvb1JVX19BomWfrGDOXrqz3n8QwlhK8+znb/bYYKmCfUMOnFW4/xnIMZxtEf6+TbWn/H4Qwncf/R+Ln9j/PkiUbWamNP1W8k+Rs1TMr1lPHnm6vq2a21v8wwdu1nquqpNYyjW22s9Vy/N4z+l4w9ceMJ0cuSvH+M5VCGsW7/tqq+cnxPfF2tPfnNSvsyVEP91HhMnp/ke3L0vAZsMpK5LWT88H1bkn/eWnsww5nB12T40Howyf+RL70nvj9D3fknMkwR/KpxG+/LMA3yuzL0mnxdhsHH6/HNSfZV1Z9lqId/ZfvStV5+JsnesbzgmtWe3Fr7gwxJxPsyjEtbOXj3f09yd5LfzVD+8LoMteOfzzCu6r+N239ua+3XxsdvrmEmyXsyjElIa+3TSV6aZE+GspdLksz2Vl2YoXThWL2Rv57kWTUzy+cJ+NUMSeuBDB/sT1xkdGykXpRhQpFPZTir+OYkX3US+1nN9Rlel9+qqs8l+VCGMW1prX0sySsyDDg/lCEZP7jaRtpwuYUrkvxkhtfhrnxpgpIbk1w6vg7/cR1/07/IcKw/leF4/OqK3X1Pkg+01v7HeP9JlyRore3P0Bv878aY78sw9uBEvGXc7wfHOP6/rEgqAdartfavk/xEhsTrkfHnTRmStf/nGE+7KcNn71quz1AaP+vCPLn9WulNGdr7k/FDGb43/HGG8XpPxL5WG3uqWmufyzA5yMsy9EY9PO7ryMRWP5JheMfDGcaJ/coam5vX94ZkGAP3pvH2C5L89xVDHX4gw6UpPp6hvbolw9CXdWmtfSFDm/jdGdrS1yf5gdbaJ9Z8It2roawXWK+q+j8zjDd70xrr7EpyaWvtVcdah1NXVfsyDEi/p6rOzTD72fnNBxuwxY1VFB9J8j+31r54jHW+LMPn5uVj7xATqKrvyTAx1zXj/dcnuae19vrFRsZmIJkDNoWq+htJ/nZrbV3TXwPAIownfH9dAs1GkMwBAAB0yJg5AACADknmAAAAOrTU15k755xz2o4dOxYdBgBzcOedd366tbZ90XH0QhsJsDWs1T4udTK3Y8eO7N+/f9FhADAHVfXAomPoiTYSYGtYq31UZgkAANAhyRwAAECHTimZq6q3VNWjVXXPzLKzq+q9VfXJ8fdZ4/Kqql+uqvuq6qNV9ZxTDR4AAGCrOtWeubcmeeGKZbuT3NFauyTJHeP9JPnuJJeMP7uSvOEU9w0AALBlnVIy11r7YJI/WbH4qiR7x9t7k1w9s/xtbfChJGdW1Xmnsn8AAICtaooxc+e21g6Ntx9Ocu54+/wkD86sd3Bc9iRVtauq9lfV/sOHD08QHgAAQP8mnQCltdaStBN8zg2ttZ2ttZ3bt7vcEAAAwGqmSOYeOVI+Of5+dFz+UJILZ9a7YFwGAADACZoimbstybXj7WuT3Dqz/AfGWS2fm+SzM+WYAAAAnIBtp/LkqropyfOTnFNVB5O8NsmeJO+squuSPJDkmnH19yS5Isl9ST6f5OWnsm8AAICt7JSSudba9x7joctXWbclecWp7A8AAIDBpBOgAAAAMA3JHAAAQIckcwAAAB2SzAEAAHRIMgcAANChU5rNEthYO3bf/sTtA3uuXGAkALA8ZtvHRBsJR+iZAwAA6JBkDgAAoEPKLGFJKSkBAGAteuYAAAA6JJkDAADokGQOAACgQ5I5AACADknmAAAAOiSZAwAA6JBkDgAAoEOSOQAAgA5J5gAAADokmQMAAOjQtkUHAFvNjt23PU59qgAAG/JJREFUP3H7wJ4rFxgJAAA90zMHAADQIckcAABAhyRzAAAAHZLMAQAAdEgyBwAA0CHJHAAAQIckcwAAAB2SzAEAAHRIMgcAANAhyRwAAECHti06AAAA2LH79ifdP7DnygVFAv3QMwcAANAhyRwAAECHJHMAAAAdkswBAAB0SDIHAADQIbNZAgDQldmZL816yVamZw4AAKBDkjkAAIAOSeYAYINV1Vuq6tGqumdm2dlV9d6q+uT4+6xxeVXVL1fVfVX10ap6zuIiB6AnkjkA2HhvTfLCFct2J7mjtXZJkjvG+0ny3UkuGX92JXnDnGIEoHMmQIEFmh3ADWwerbUPVtWOFYuvSvL88fbeJB9I8upx+dtaay3Jh6rqzKo6r7V2aD7RAtArPXMAMB/nziRoDyc5d7x9fpIHZ9Y7OC4DgDVJ5gBgzsZeuHaiz6uqXVW1v6r2Hz58eILIAOiJZA4A5uORqjovScbfj47LH0py4cx6F4zLjtJau6G1trO1tnP79u2TBgvA8jNmDiZmXBwwui3JtUn2jL9vnVn+I1V1c5JvSfJZ4+UAWA/JHABssKq6KcNkJ+dU1cEkr82QxL2zqq5L8kCSa8bV35PkiiT3Jfl8kpfPPWAAuiSZA4AN1lr73mM8dPkq67Ykr5g2IgA2I2PmAAAAOiSZAwAA6JBkDgAAoEOSOQAAgA5J5gAAADokmQMAAOiQZA4AAKBDkjkAAIAOSeYAAAA6JJkDAADokGQOAACgQ9sWHQBw6nbsvv2J2wf2XLnASAAAmBc9cwAAAB2SzAEAAHRIMgcAANChyZK5qvrxqvpYVd1TVTdV1RlVdXFV7auq+6rqHVV1+lT7BwAA2MwmSeaq6vwkP5ZkZ2vtbyU5LcnLkrwuyS+21v56ks8kuW6K/QMAAGx2U85muS3Jl1fVF5M8NcmhJC9I8g/Hx/cm+Zkkb5gwBgAAOjQ7UzOwukl65lprDyX5+SR/lCGJ+2ySO5M81lp7fFztYJLzp9g/AADAZjdJz1xVnZXkqiQXJ3ksyX9I8sJ1PndXkl1JctFFF00RHkzO2UQAAKY21QQo35nkU621w621LyZ5d5LnJTmzqo4kkBckeWjlE1trN7TWdrbWdm7fvn2i8AAAAPo2VTL3R0meW1VPrapKcnmSjyd5f5KXjOtcm+TWifYPAACwqU01Zm5fkluSfDjJ3eN+bkjy6iQ/UVX3JXlGkhun2D8AAMBmN9lslq211yZ57YrF9ye5bKp9AgDQj40YY75yGwf2XHnK24ReTHbRcAAAAKYjmQMAAOjQlBcNB5bAWiUsSlEAAPqlZw4AAKBDkjkAAIAOSeYAAAA6JJkDAADokGQOAACgQ5I5AACADknmAAAAOiSZAwAA6JBkDgAAoEPbFh0AAADM247dtz/p/oE9Vy4oEjh5euYAAAA6JJkDAADokDJLAAA2pRMppZxdV8klvdAzBwAA0CE9c7ABVp75AwCAqemZAwAA6JBkDgAAoEPKLKFDyjoBANAzBwAA0CHJHAAAQIckcwAAAB2SzAEAAHRIMgcAANAhyRwAAECHXJoAOuFyBAAAzNIzBwAA0CHJHAAAQIckcwAwR1X141X1saq6p6puqqozquriqtpXVfdV1Tuq6vRFxwnA8jNmDgDmpKrOT/JjSS5trf2/VfXOJC9LckWSX2yt3VxVb0xyXZI3LDBU6JYx5mwleuYAYL62JfnyqtqW5KlJDiV5QZJbxsf3Jrl6QbEB0BHJHADMSWvtoSQ/n+SPMiRxn01yZ5LHWmuPj6sdTHL+YiIEoCeSOQCYk6o6K8lVSS5O8jVJnpbkhSfw/F1Vtb+q9h8+fHiiKAHohWQOAObnO5N8qrV2uLX2xSTvTvK8JGeOZZdJckGSh1Z7cmvthtbaztbazu3bt88nYgCWlmQOAObnj5I8t6qeWlWV5PIkH0/y/iQvGde5NsmtC4oPgI6YzRIA5qS1tq+qbkny4SSPJ/m9JDckuT3JzVX1r8ZlNy4uSjhxK2eQPLDnygVFAluLZA5IoiGGeWmtvTbJa1csvj/JZQsIB4COKbMEAADokGQOAACgQ5I5AACADknmAAAAOiSZAwAA6JBkDgAAoEOSOQAAgA65zhwAAHOz8rqmwMnTMwcAANAhyRwAAECHlFnCOq0sCzmw58oFRQIAAHrmAAAAuiSZAwAA6JBkDgAAoEPGzAEAsCW4LAKbjZ45AACADknmAAAAOqTMEgCAyShthOlI5mDGZriW3Ik0mhpYAIB+KbMEAADokGQOAACgQ5I5AACADknmAAAAOiSZAwAA6JBkDgAAoEOTJXNVdWZV3VJVn6iqe6vqW6vq7Kp6b1V9cvx91lT7BwAA2MymvM7c9Ul+s7X2kqo6PclTk7wmyR2ttT1VtTvJ7iSvnjAGAAA4IZvhurNsDZP0zFXVVyX5jiQ3Jklr7QuttceSXJVk77ja3iRXT7F/AACAzW6qnrmLkxxO8itV9Q1J7kzyyiTnttYOjes8nOTclU+sql1JdiXJRRddNFF4cOpWnrUDAIB5mmrM3LYkz0nyhtbaNyX58wwllU9orbUkbeUTW2s3tNZ2ttZ2bt++faLwAAAA+jZVMncwycHW2r7x/i0ZkrtHquq8JBl/PzrR/gEAADa1SZK51trDSR6sqq8fF12e5ONJbkty7bjs2iS3TrF/AACAzW7K2Sx/NMnbx5ks70/y8gzJ4zur6rokDyS5ZsL9AwCwQczwCMtnsmSutXZXkp2rPHT5VPsEAADYKia7aDgAAADTkcwBAAB0SDIHAADQIckcAABAhyRzAAAAHZLMAQAAdEgyBwAA0CHJHAAAQIckcwAAAB2SzAEAAHRIMgcAANChbYsOAACAzWXH7tsXHcKGmv17Duy5coGRwJPpmQMAAOiQnjk2rbXOojnDBgBA7/TMAQAAdEgyBwAA0CFllmwJJzsQe7MN4AYAYPPQMwcAANAhyRwAAECHJHMAAAAdkswBwBxV1ZlVdUtVfaKq7q2qb62qs6vqvVX1yfH3WYuOE4DlJ5kDgPm6PslvttaeleQbktybZHeSO1prlyS5Y7wPAGuSzAHAnFTVVyX5jiQ3Jklr7QuttceSXJVk77ja3iRXLyZCAHoimQOA+bk4yeEkv1JVv1dVb66qpyU5t7V2aFzn4STnLixCALrhOnMAMD/bkjwnyY+21vZV1fVZUVLZWmtV1VZ7clXtSrIrSS666KKpY4U1uRYrLJ6eOQCYn4NJDrbW9o33b8mQ3D1SVeclyfj70dWe3Fq7obW2s7W2c/v27XMJGIDlJZkDgDlprT2c5MGq+vpx0eVJPp7ktiTXjsuuTXLrAsIDoDPKLAFgvn40ydur6vQk9yd5eYaTq++squuSPJDkmgXGxxYzWy55YM+VC4wEOFGSOQCYo9baXUl2rvLQ5fOOBYC+KbMEAADokGQOAACgQ5I5AACADknmAAAAOiSZAwAA6JDZLIHjmp22OjF1NQDAMtAzBwAA0CHJHAAAQIckcwAAAB0yZg5Y1cpxcgAALBfJHAAAq3Ji72gmBWOZKLMEAADokGQOAACgQ5I5AACADhkzBwBAEmPkoDd65gAAADokmQMAAOiQZA4AAKBDkjkAAIAOSeYAAAA6ZDZLtjwzdwEA0CM9cwAAAB2SzAEAAHRImSUAwBZieMHGmj2eB/ZcucBI2Ir0zAEAAHRIMgcAANAhyRwAAECHJHMAAAAdkswBAAB0yGyWAACwAVbOFGp2S6amZw4AAKBDeuaAU+IsJADAYuiZAwAA6JBkDgAAoEOSOQAAgA5NlsxV1WlV9XtV9Rvj/Yural9V3VdV76iq06faNwAAwGY3Zc/cK5PcO3P/dUl+sbX215N8Jsl1E+4bAABgU5skmauqC5JcmeTN4/1K8oIkt4yr7E1y9RT7BgAA2Aqm6pn7pSQ/leSvxvvPSPJYa+3x8f7BJOev9sSq2lVV+6tq/+HDhycKDwAAoG8bnsxV1YuSPNpau/Nknt9au6G1trO1tnP79u0bHB0AAMDmMMVFw5+X5MVVdUWSM5J8ZZLrk5xZVdvG3rkLkjw0wb4BAAC2hA3vmWut/XRr7YLW2o4kL0vy262170vy/iQvGVe7NsmtG71vAACArWKKnrljeXWSm6vqXyX5vSQ3znHfbBI7dt/+pPsH9ly5oEi2tpWvAwAA8zdpMtda+0CSD4y3709y2ZT7AwAA2CqmvM4cAAAAE5lnmSUAAGwZs8MSDA1hCnrmAAAAOiSZAwAA6JBkDgAAoEOSOQAAgA5J5gAAADpkNksAgE1grZkTZx8DNg89cwAAAB2SzAEAAHRIMgcAANAhY+YAYM6q6rQk+5M81Fp7UVVdnOTmJM9IcmeS72+tfWGRMdI3Y+Rga5DMsWlouICOvDLJvUm+crz/uiS/2Fq7uaremOS6JG9YVHAA9EGZJQDMUVVdkOTKJG8e71eSFyS5ZVxlb5KrFxMdAD2RzAHAfP1Skp9K8lfj/Wckeay19vh4/2CS81d7YlXtqqr9VbX/8OHD00cKwFKTzAHAnFTVi5I82lq782Se31q7obW2s7W2c/v27RscHQC9MWYOAObneUleXFVXJDkjw5i565OcWVXbxt65C5I8tMAYAeiEnjkAmJPW2k+31i5ore1I8rIkv91a+74k70/yknG1a5PcuqAQAeiIZA4AFu/VSX6iqu7LMIbuxgXHA0AHlFkCwAK01j6Q5APj7fuTXLbIeADoj545AACADknmAAAAOiSZAwAA6JAxc3Rtx+7bFx0CJ2nla3dgz5ULigQAoE965gAAADokmQMAAOiQZA4AAKBDkjkAAIAOSeYAAAA6ZDZLAACYs9lZnc3ozMnSMwcAANAhPXPAhlrr2n/OPAIAbBw9cwAAAB3SMwcA0KG1KiFYPl4vpiCZY+n58AMAgKMpswQAAOiQZA4AAKBDkjkAAIAOSeYAAAA6ZAIUAABYIrOTv7lGK2vRMwcAANAhyRwAAECHlFkCS2fltQWVmAAAHE3PHAAAQIckcwAAAB1SZgnMzcryyfU+BgDA0fTMAQAAdEgyBwAA0CHJHAAAQIckcwAAAB2SzAEAAHRIMgcAANAhlyZg6ZiiHgAAjk/PHAAAQIckcwAAAB2SzAEAAHRIMgcAANAhyRwAAECHzGYJAAALtNZM3isfO7DnyqnDoSN65gAAADqkZ46l4NpyAABwYvTMAQAAdEgyBwAA0CFlliyEskoAADg1kyRzVXVhkrclOTdJS3JDa+36qjo7yTuS7EhyIMk1rbXPTBEDAECPZk94mrmQlbw/mDVVmeXjSX6ytXZpkucmeUVVXZpkd5I7WmuXJLljvA8AAMAJmiSZa60daq19eLz9uST3Jjk/yVVJ9o6r7U1y9RT7BwAA2OwmnwClqnYk+aYk+5Kc21o7ND70cIYyzJXr76qq/VW1//Dhw1OHBwAA0KVJk7mq+ook70ryqtban84+1lprGcbTZcXyG1prO1trO7dv3z5leAAAAN2aLJmrqqdkSOTe3lp797j4kao6b3z8vCSPTrV/AACAzWyq2SwryY1J7m2t/cLMQ7cluTbJnvH3rVPsHwBgM3JpH9ZipsutZ6rrzD0vyfcnubuq7hqXvSZDEvfOqrouyQNJrplo/8AmonECADjaJMlca+2/JqljPHz5FPsEAADYSiafzRIAAICNN1WZJQCwQlVdmORtGS7N05Lc0Fq7vqrOTvKOJDuSHEhyTWvtM4uKk423cqybknFgI+iZA4D5eTzJT7bWLk3y3CSvqKpLk+xOckdr7ZIkd4z3AWBNkjkAmJPW2qHW2ofH259Lcm+S85NclWTvuNreJFcvJkIAeqLMEgAWoKp2JPmmJPuSnNtaOzQ+9HCGMszVnrMrya4kueiii6YPElhqLlWBZI7JGB/AFLyv2Ayq6iuSvCvJq1prfzpcnnXQWmtV1VZ7XmvthiQ3JMnOnTtXXQeArUOZJQDMUVU9JUMi9/bW2rvHxY9U1Xnj4+cleXRR8QHQDz1zADAnNXTB3Zjk3tbaL8w8dFuSa5PsGX/fuoDwgE1EJcvWIJkDgPl5XpLvT3J3Vd01LntNhiTunVV1XZIHklyzoPgA6IhkDgDmpLX2X5PUMR6+fJ6xANA/yRwAwJIyWyGwFhOgAAAAdEjPHBtqrTOIzi4CAMDGkcwBAMzZ7AlOswwCJ0uZJQAAQIckcwAAAB1SZgkAsEDGlAMnS88cAABAhyRzAAAAHVJmyXGtLP8w6xa9MFscALCZ6ZkDAADokGQOAACgQ5I5AACADhkzBwAww1hxNjvv8c1DzxwAAECHJHMAAAAdUmYJAHCSXAIFWCTJHNC19X6RWjk+YJYvYABAj5RZAgAAdEgyBwAA0CFllluIaWgBAGDz0DMHAADQIT1zAABAkhOr5DKb6+LpmQMAAOiQnrkt7GTPpjgLAwAAiyeZAwDYACYaY7Nb65qtJ7sd/yenRpklAABAhyRzAAAAHVJmCWwaJ1v+oTQKNo+NGA8OfIn/jeWmZw4AAKBDkjkAAIAOKbPcACdborXMpV3r7VLX9c5mtMhZttb6nzrZWJb5swYAOHmSOQCACTjhyTLxfjxxPVxCQZklAABAhyRzAAAAHVJmOYF5d8luxP50vcPq1hpvdrKPTRHbspZ/ALD8pvgeqI2aDz1zAAAAHZLMAQAAdEiZJQBwlBO5TMZa5VRTlFot6+VDYCvbqP+NKYYPbeYyzy2XzG2GF3etf5bN8PcBp84XTgDY/JRZAgAAdGjL9cwBAMvnRGaHnWJ/wPKZx+dC77NuSuZmLHqa8bWc7BtWYwXz4/8NAJgnZZYAAAAd0jMHAFvUvKtOFl3lAizGoitX1ltK2WPppp45AACADm35nrkTmeZ/aos+awEc37KOXz2R7W/ENcH0sADA4m35ZA4AGGzESYeTPbEwhSlKpoCN1cv/17KexFRmCQAA0CHJHAAAQIeUWQJsYctUEkc/lum9sEyxANNapv/3ZYlFzxwAAECHJHMAAAAd2hJlllN0g653m8vSBQv0z+VSAIBZc0/mquqFSa5PclqSN7fW9sw7BgBYNtrHJ3MyAZjCZvtsmWuZZVWdluTfJ/nuJJcm+d6qunSeMQDAstE+AnAy5j1m7rIk97XW7m+tfSHJzUmumnMMALBstI8AnLB5l1men+TBmfsHk3zL7ApVtSvJrvHun1XV72/Afs9J8ukN2M48iHUaPcWa9BWvWKfRU6yp121IvM/ciFg6ddz2MZmkjezqfZa+4hXrNMQ6nZ7i7SbWqdvHpZsApbV2Q5IbNnKbVbW/tbZzI7c5FbFOo6dYk77iFes0eoo16S/eXm10G9nb69ZTvGKdhlin01O8Yv2SeZdZPpTkwpn7F4zLAGAr0z4CcMLmncz9bpJLquriqjo9ycuS3DbnGABg2WgfAThhcy2zbK09XlU/kuQ/Z5h6+S2ttY/NYdcbWrY5MbFOo6dYk77iFes0eoo16S/epaJ9XLee4hXrNMQ6nZ7iFeuoWmtTbh8AAIAJzLvMEgAAgA0gmQMAAOjQpkzmqurfVNUnquqjVfVrVXXmMdZ7YVX9flXdV1W75x3nGMNLq+pjVfVXVXXMaUur6kBV3V1Vd1XV/nnGOBPDemNdhuN6dlW9t6o+Of4+6xjr/eV4TO+qqrlONnC841RVX1ZV7xgf31dVO+YZ3yrxHC/eH6yqwzPH839bUJxvqapHq+qeYzxeVfXL49/x0ap6zrxjXBHP8eJ9flV9dua4/vN5xzjGcWFVvb+qPj5+DrxylXWW6thyNO3jdLSRGx5jN21kL+3jGEs3bWQv7eMYy+LayNbapvtJ8r8m2Tbefl2S162yzmlJ/jDJ1yY5PclHkly6gFifneTrk3wgyc411juQ5JwFH9fjxrpEx/VfJ9k93t692ntgfOzPFnQsj3uckvzTJG8cb78syTsW+NqvJ94fTPLvFhXjTBzfkeQ5Se45xuNXJPlPSSrJc5PsW/J4n5/kN5bguJ6X5Dnj7acn+YNV3gNLdWz9rPo6ah8XGO8SHVtt5HxjXYr2cYylmzayl/ZxjGVhbeSm7Jlrrf1Wa+3x8e6HMlyvZ6XLktzXWru/tfaFJDcnuWpeMR7RWru3tfb7897vyVhnrEtxXMd97h1v701y9QJiWMt6jtPs33BLksurquYY46xleV2Pq7X2wSR/ssYqVyV5Wxt8KMmZVXXefKI72jriXQqttUOttQ+Ptz+X5N4k569YbamOLUfTPk5HG7mhemojl+U1XZee2she2sdksW3kpkzmVvjHGbLglc5P8uDM/YM5+qAvk5bkt6rqzqratehg1rAsx/Xc1tqh8fbDSc49xnpnVNX+qvpQVc2zMVvPcXpinfHL12eTPGMu0R1tva/rPxhLB26pqgtXeXwZLMt79ER8a1V9pKr+U1X9zUUHM5YzfVOSfSse6vHYbmXax/lblmOrjdw4m6l9TJbnPbpeS9U+JvNvI+d6nbmNVFXvS/LVqzz0z1prt47r/LMkjyd5+zxjW2k9sa7Dt7fWHqqq/ynJe6vqE+MZiw21QbHOxVqxzt5prbWqOtY1OJ45HtevTfLbVXV3a+0PNzrWLeLXk9zUWvuLqvonGc6YvmDBMW0GH87wPv2zqroiyX9Mcsmigqmqr0jyriSvaq396aLi4Ni0j9O0j4k2Uht50rSP01iq9jFZTBvZbTLXWvvOtR6vqh9M8qIkl7exUHWFh5LMnhm5YFy24Y4X6zq38dD4+9Gq+rUM3fob3lhtQKxLcVyr6pGqOq+1dmjswn70GNs4clzvr6oPZDiTMo+Gaj3H6cg6B6tqW5KvSvLHc4htNceNt7U2G9ubM4zJWEZze49uhNnGoLX2nqp6fVWd01r79LxjqaqnZGik3t5ae/cqq3R1bDcr7eM07eO4D22kNnKlzdQ+Jh19ji9T+5gsro3clGWWVfXCJD+V5MWttc8fY7XfTXJJVV1cVadnGDw715ma1quqnlZVTz9yO8MA9lVn9lkCy3Jcb0ty7Xj72iRHnTGtqrOq6svG2+ckeV6Sj88pvvUcp9m/4SVJfvsYX7zm4bjxrqj7fnGGevFldFuSHxhnlXpuks/OlBstnar66iPjQKrqsgyf23P/wjLGcGOSe1trv3CM1bo6tluR9nHhluXYaiM3zmZqH5OOPseXpX0c97+4NrItwQwwG/2T5L4MNal3jT9HZjv6miTvmVnvigyzzfxhhhKJRcT69zLUzP5FkkeS/OeVsWaYIekj48/HljnWJTquz0hyR5JPJnlfkrPH5TuTvHm8/W1J7h6P691JrptzjEcdpyT/MsOXrCQ5I8l/GN/Pv5PkaxdxLE8g3v97fH9+JMn7kzxrQXHelORQki+O79frkvxwkh8eH68k/378O+7OGrPkLUm8PzJzXD+U5NsWFOe3Zxib9NGZz9YrlvnY+ln1ddQ+LjDeJTq22sj5xroU7eMYSzdt5DpiXYr2cYxlYW1kjRsHAACgI5uyzBIAAGCzk8wBAAB0SDIHAADQIckcAABAhyRzAAAAHZLMAQAAdEgyBwAA0KH/H/f9ip90EedXAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1080x1080 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSuNZhYJPTgL",
        "colab_type": "text"
      },
      "source": [
        "Don't Run! Old Robust fit algorithm\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KukSaal_PYhY",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "#@title Default title text\n",
        "print(fdgldfc)\n",
        "def robust_fit(data,preds,estimator=linear_model.RANSACRegressor() ):\n",
        "  node_lines = finder(data,preds)\n",
        "  x,y=data.x[:,0],data.x[:,1]\n",
        "  errors,models=[],[]\n",
        "  parameters=[]\n",
        "  for i in range(1,4):\n",
        "    \n",
        "    nodes=np.where(node_lines==i)\n",
        "    \n",
        "    if np.size(nodes)>1 :\n",
        "      \n",
        "      model = linear_model.RANSACRegressor()\n",
        "      model.fit( x[nodes].reshape(-1, 1)  , y[nodes] )\n",
        "      \n",
        "      parameters.append(  [ model.estimator_.coef_, model.predict(  np.zeros(1).reshape(-1,1) ) ]) \n",
        "      error = mean_squared_error( model.predict(x[nodes].reshape(-1, 1)), y[nodes] )\n",
        "      error= np.round(error,2)\n",
        "      errors.append( error )\n",
        "      models.append( model )\n",
        "    \n",
        "    else  :\n",
        "\n",
        "      models.append('N/A')\n",
        "      errors.append('N/A')\n",
        "      parameters.append('N/A')\n",
        "  \n",
        "  return [models,errors,parameters,node_lines]\n",
        "\n",
        "def plot_classified_line(data,preds,Track,trackre ):\n",
        "\n",
        "  models,errors,parameters,node_lines=robust_fit(data,preds,linear_model.RANSACRegressor())\n",
        "  x,y=data.x[:,0],data.x[:,1]\n",
        "  colors={'1':'r','2':'g','3':'b' }\n",
        "  fig=plt.figure(figsize=(10,10))\n",
        "  ax=fig.add_subplot(111)\n",
        "\n",
        "  if (node_lines==0).any()== True:\n",
        "    nodes=np.where(node_lines==0)\n",
        "    plt.plot(x[nodes],y[nodes], 'k'+'o' , label = 'Not Track')\n",
        "  for i in range(1,4):\n",
        "    \n",
        "    nodes=np.where(node_lines==i)\n",
        "    plt.plot(x[nodes],y[nodes],colors[str(i)] +'o' )\n",
        "\n",
        "  for i in [2,3]:\n",
        "    \n",
        "    nodes=np.where(node_lines==i)\n",
        "    \n",
        "\n",
        "\n",
        "    if np.size(nodes)>1 :\n",
        "      \n",
        "      model=models[i-1]\n",
        "      error=errors[i-1]\n",
        "      \n",
        "      x_guess=np.linspace(0,torch.max(x[nodes]),100)\n",
        "      y_guess = model.predict( x_guess[:, np.newaxis] )\n",
        "      x_line=np.linspace(torch.min(x[nodes]),torch.max(x[nodes]),100)\n",
        "\n",
        "      slope_mc=Track[i-1]\n",
        "      c_mc = y[nodes][0] - x[nodes][0] * slope_mc\n",
        "      slope_recon_ = trackre[2*i-4]\n",
        "      c_recon= y[nodes][0] - x[nodes][0] * slope_recon_ \n",
        "\n",
        "      plt.plot(x_guess,y_guess,'--'+colors[str(i)],label=\"GNN{} Error: {:e}, \".format(i-1, \n",
        "          torch.abs( np.round( (slope_mc-parameters[i-1][0])/slope_mc ,2) ).tolist()[0] ))\n",
        "      \n",
        "\n",
        "      plt.plot( torch.tensor(x_line), torch.tensor(x_line) * slope_recon_ + c_recon ,colors[str(i)], label=\"recon{} Error: {:e}, \".format(i-1, \n",
        "          torch.abs( np.round( (slope_mc-slope_recon_)/slope_mc ,2) ).tolist() )  )   \n",
        "\n",
        "#. format( error , np.round(parameters[i-1][0],2),np.round(parameters[i-1][1],2)   )   )\n",
        "      \n",
        "      \n",
        "      plt.plot(x_line,c_mc + torch.tensor(x_line)*slope_mc,'k',label='MC Track', alpha=0.4) \n",
        "      \n",
        "            \n",
        "      #ax.errorbar(x[nodes],y[nodes],yerr= np.ones(np.size(nodes,1) )*0.03,fmt='none', ecolor=colors[str(i)] )\n",
        "  plt.legend()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdBGjDLpjfpy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_tracks[1008]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}